{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "def print_table(matrix):\n",
    "    for row in matrix:\n",
    "        for element in row:\n",
    "            print(element, end='\\t')  # Separate elements by a tab (or any delimiter you prefer)\n",
    "        print()  # Move to the next line for the next row\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def modern_style_scrape(link):\n",
    "    response = make_request(link)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        # print(link)\n",
    "        driver.get(link)\n",
    "        # driver.implicitly_wait(2) # wait a bit\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "        driver.quit()\n",
    "\n",
    "    individual_stats = soup.find('section', id='individual-stats')\n",
    "    tables = individual_stats.find_all('table')\n",
    "\n",
    "    score_table = soup.find('table')\n",
    "    score_table = score_table.find_all('td')\n",
    "    for i in range(1, len(score_table)):\n",
    "        try:\n",
    "            x = int(score_table[i+1].text)\n",
    "        except:\n",
    "            ascore = float(score_table[i].text)\n",
    "            home_team = score_table[i+1].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "            break\n",
    "\n",
    "    away_team = score_table[0].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "    hscore = float(score_table[-1].text)\n",
    "\n",
    "    home_team = home_team.replace(\"Winner\", \"\")\n",
    "    away_team = away_team.replace(\"Winner\", \"\")\n",
    "\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get date\n",
    "    big_html = soup.text\n",
    "    date_index = big_html.find('Date:')\n",
    "    date_endex = big_html.find('Site:')\n",
    "    date = big_html[date_index + 6: date_endex].strip()\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "\n",
    "    # make gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "\n",
    "    if home_team == 'texas':\n",
    "        tex_pass = tables[1]\n",
    "        tex_rush = tables[3]\n",
    "        tex_rec = tables[5]\n",
    "    else:\n",
    "        tex_pass = tables[0]\n",
    "        tex_rush = tables[2]\n",
    "        tex_rec = tables[4]\n",
    "\n",
    "    tex_pass_stats = tex_pass.find_all('td')\n",
    "    for i in range(len(tex_pass_stats)):  # convert passers to text\n",
    "        tex_pass_stats[i] = tex_pass_stats[i].text.strip()\n",
    "    passer_temp = []\n",
    "    tex_pass_stats_final = []\n",
    "    for i in range(len(tex_pass_stats)):\n",
    "        passer_temp.append(tex_pass_stats[i])\n",
    "        if len(passer_temp)/8 == 1:\n",
    "            tex_pass_stats_final.append(passer_temp)\n",
    "            passer_temp = []\n",
    "    for i in range(len(tex_pass_stats_final)):\n",
    "        for j in range(1, len(tex_pass_stats_final[i])):\n",
    "            tex_pass_stats_final[i][j] = float(tex_pass_stats_final[i][j])\n",
    "    tex_pass_stats_final = pd.DataFrame(tex_pass_stats_final)\n",
    "    tex_pass_stats_final.columns = ['Player', 'Completions', 'Pass Attempts', 'Pass Yards', 'Passing TDs', 'Interceptions', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    tex_rush_stats = tex_rush.find_all('td')\n",
    "    for i in range(len(tex_rush_stats)):  # convert passers to text\n",
    "        tex_rush_stats[i] = tex_rush_stats[i].text.strip()\n",
    "    rusher_temp = []\n",
    "    tex_rush_stats_final = []\n",
    "    for i in range(len(tex_rush_stats)):\n",
    "        rusher_temp.append(tex_rush_stats[i])\n",
    "        if len(rusher_temp)/8 == 1:\n",
    "            tex_rush_stats_final.append(rusher_temp)\n",
    "            rusher_temp = []\n",
    "    for i in range(len(tex_rush_stats_final)):\n",
    "        for j in range(1, len(tex_rush_stats_final[i])):\n",
    "            tex_rush_stats_final[i][j] = float(tex_rush_stats_final[i][j])\n",
    "    tex_rush_stats_final = pd.DataFrame(tex_rush_stats_final)\n",
    "    tex_rush_stats_final.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    tex_rec_stats = tex_rec.find_all('td')\n",
    "    for i in range(len(tex_rec_stats)):  # convert passers to text\n",
    "        tex_rec_stats[i] = tex_rec_stats[i].text.strip()\n",
    "    recer_temp = []\n",
    "    tex_rec_stats_final = []\n",
    "    for i in range(len(tex_rec_stats)):\n",
    "        recer_temp.append(tex_rec_stats[i])\n",
    "        if len(recer_temp)/5 == 1:\n",
    "            tex_rec_stats_final.append(recer_temp)\n",
    "            recer_temp = []\n",
    "    for i in range(len(tex_rec_stats_final)):\n",
    "        for j in range(1, len(tex_rec_stats_final[i])):\n",
    "            tex_rec_stats_final[i][j] = float(tex_rec_stats_final[i][j])\n",
    "    tex_rec_stats_final = pd.DataFrame(tex_rec_stats_final)\n",
    "    tex_rec_stats_final.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        tex_pass_stats_final, tex_rush_stats_final, how = \"outer\", on = \"Player\")\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        full_game_stats, tex_rec_stats_final, how = 'outer', on = \"Player\")\n",
    "\n",
    "    full_game_stats = full_game_stats.fillna(0)\n",
    "\n",
    "    full_game_stats['GameID'] = gameid\n",
    "    full_game_stats['Date'] = date\n",
    "    full_game_stats['Home Team'] = home_team\n",
    "    full_game_stats['Away Team'] = away_team\n",
    "    full_game_stats['Home Score'] = hscore\n",
    "    full_game_stats['Away Score'] = ascore\n",
    "    full_game_stats['Texas Result'] = tex_win\n",
    "    full_game_stats['Link'] = link\n",
    "\n",
    "    return full_game_stats\n",
    "\n",
    "def def_scrape_1(temp_box_soup, year):\n",
    "    temp = temp_box_soup.find('font', string = \"Defensive Statistics\")\n",
    "    temp = temp.find_next('font', string = \"Defensive Statistics\")\n",
    "    temp = temp.find_next('pre').text\n",
    "    temp = temp.replace('Texas Longhorns     ', 'Texas               ')\n",
    "    temp = temp.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Truncate box score for def stats\n",
    "    def_start = temp.find('Texas               \\n## Player               Solo  Ast  Tot  TFL/Yds  FF FR-Yd Intc BrUp Blkd Sack/Yds QH')\n",
    "    def_temp = temp[def_start:]\n",
    "\n",
    "    # Get def stats\n",
    "    def_stats = []    \n",
    "    line_break = def_temp.find('\\n')\n",
    "    def_temp = def_temp[line_break + 1:]\n",
    "    line_break = def_temp.find('\\n')\n",
    "    header = '## Last  First  Solo  Ast  Tot  TFL tfl_yds  FF FR fr_yd Int int_yds BrUp Blkd Sack sack_yds QH'.split()\n",
    "    # def_stats.append(header)\n",
    "    def_temp = def_temp[line_break:]\n",
    "    line_break = def_temp.find('\\n')\n",
    "    def_temp = def_temp[line_break + 1:]\n",
    "\n",
    "    # Now def temp has no header\n",
    "    line_break = def_temp.find('\\n')\n",
    "    def_temp = def_temp[line_break + 1:]\n",
    "\n",
    "    while True:\n",
    "        line_break = def_temp.find('\\n')\n",
    "        line = def_temp[0:line_break + 1]\n",
    "\n",
    "        if line_break == 0:\n",
    "            break\n",
    "\n",
    "        line = line.replace('--', '-')\n",
    "\n",
    "        game_stat = line.split()\n",
    "\n",
    "        for i in range(len(game_stat)):\n",
    "            if game_stat[i] == '.':\n",
    "                game_stat[i] = ''\n",
    "\n",
    "        try:\n",
    "            first_name_catch = re.search(r',\\s*(.*)$', game_stat[1]).group(1)\n",
    "            if first_name_catch:\n",
    "                last_name_catch = re.search(r'^(.*?),', game_stat[1]).group(1)\n",
    "                game_stat[1] = last_name_catch\n",
    "                game_stat.insert(1, first_name_catch)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if len(game_stat) == 13:\n",
    "            game_stat.insert(2, '')\n",
    "        \n",
    "        if len(game_stat) == 15:\n",
    "            game_stat[2] = str(game_stat[2]) + ' ' + str(game_stat[3])\n",
    "            game_stat.pop(3)\n",
    "\n",
    "        if '/' in game_stat[6]:\n",
    "            parts = game_stat[6].split('/')\n",
    "            game_stat[6:7] = parts\n",
    "        else: \n",
    "            game_stat[6:7] = ['','']\n",
    "\n",
    "        if '/' in game_stat[13]:\n",
    "            parts = game_stat[13].split('/')\n",
    "            game_stat[13:14] = parts\n",
    "        else: \n",
    "            game_stat[13:14] = ['','']\n",
    "        \n",
    "        if '-' in game_stat[9]:\n",
    "            parts = game_stat[9].split('-')\n",
    "            game_stat[9:10] = parts\n",
    "        else: \n",
    "            game_stat[9:10] = ['','']\n",
    "\n",
    "        if '-' in game_stat[11]:\n",
    "            parts = game_stat[11].split('-')\n",
    "            game_stat[11:12] = parts\n",
    "        else: \n",
    "            game_stat[11:12] = ['','']\n",
    "\n",
    "        game_stat[1] = game_stat[1].replace(',', '')\n",
    "        game_stat[2] = game_stat[2].replace(',', '')\n",
    "\n",
    "        for i in range(3, 3 + len(game_stat[3:])):\n",
    "            if game_stat[i]:\n",
    "                game_stat[i] = float(game_stat[i])\n",
    "            else:\n",
    "                game_stat[i] = 0\n",
    "\n",
    "        def_stats.append(game_stat)\n",
    "        def_temp = def_temp[line_break + 1:]\n",
    "\n",
    "    if len(def_stats) > 0:\n",
    "        if year == '97':\n",
    "            totals = ['GM', '', 'Game']\n",
    "        else:\n",
    "            totals = ['GM', 'Game', '']\n",
    "\n",
    "        for j in range(3, 3 + len(def_stats[0][3:])):\n",
    "            total = 0\n",
    "            for i in range(len(def_stats)):\n",
    "                total += def_stats[i][j]\n",
    "            totals.append(total)\n",
    "        \n",
    "        \n",
    "        def_stats.append(totals)\n",
    "\n",
    "    def_stats = pd.DataFrame(def_stats, columns = header)\n",
    "\n",
    "    if year == '97':\n",
    "        def_stats['Last'], def_stats['First'] = def_stats['First'].copy(), def_stats['Last'].copy()\n",
    "    \n",
    "    return def_stats\n",
    "\n",
    "def def_scrape_2(tables, home_team):\n",
    "    if home_team == 'texas':\n",
    "        def_table = tables[32]\n",
    "    else:\n",
    "        def_table = tables[31]\n",
    "\n",
    "    def_2d = []\n",
    "    temp = []\n",
    "    i = 0\n",
    "    for row in def_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            val = val.text.strip()\n",
    "\n",
    "            if i == 1:\n",
    "                if val.find(', ') > -1:\n",
    "                    val = val.split(', ')\n",
    "                    temp.append(val[0])\n",
    "                    temp.append(val[1])\n",
    "                else:\n",
    "                    temp.append(val)\n",
    "                    temp.append('')\n",
    "\n",
    "            elif i == 5 or i == 7 or i == 8 or i == 11:\n",
    "                if val.find('-') > -1:\n",
    "                    val = val.split('-')\n",
    "                    temp.append(val[0])\n",
    "                    temp.append(val[1])\n",
    "                elif val.find('/') > -1:\n",
    "                    val = val.split('/')\n",
    "                    temp.append(val[0])\n",
    "                    temp.append(val[1])\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "                    temp.append(0)\n",
    "            else:\n",
    "                if val == '.':\n",
    "                    val = 0\n",
    "                temp.append(val)\n",
    "            i += 1\n",
    "\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(3, 3 + len(temp[3:])):\n",
    "                if temp[i]:\n",
    "                    temp[i] = float(temp[i])\n",
    "                else:\n",
    "                    temp[i] = 0\n",
    "            def_2d.append(temp)\n",
    "        temp = []\n",
    "        i = 0\n",
    "\n",
    "    if len(def_2d) > 0:\n",
    "            totals = ['GM', 'Game', '']\n",
    "\n",
    "            for j in range(3, 3 + len(def_2d[0][3:])):\n",
    "                total = 0\n",
    "                for i in range(len(def_2d)):\n",
    "                    total += def_2d[i][j]\n",
    "                totals.append(total)\n",
    "            \n",
    "            def_2d.append(totals)\n",
    "\n",
    "    def_col = ['##','Last', 'First','Solo','Ast','Tot','TFL', 'tfl_yds','FF','FR', 'fr_yd','Int','int_yds','BrUp','Blkd','Sack','sack_yds','QH']\n",
    "\n",
    "    def_data = pd.DataFrame(def_2d)\n",
    "    def_data.columns = def_col\n",
    "\n",
    "    return def_data\n",
    "\n",
    "def def_scrape_3(tables, home_team, year_frame):\n",
    "    if home_team == 'texas':\n",
    "        tex_def = tables[7]\n",
    "    else:\n",
    "        tex_def = tables[6]\n",
    "\n",
    "    tex_def_stats = tex_def.find_all('td')\n",
    "    for i in range(len(tex_def_stats)):\n",
    "        tex_def_stats[i] = tex_def_stats[i].text.strip()\n",
    "    defender_temp = []\n",
    "    tex_def_stats_final = []\n",
    "    for i in range(len(tex_def_stats)):\n",
    "        temp = tex_def_stats[i]\n",
    "        temp = temp.replace('--', '-')\n",
    "        if temp == '-':\n",
    "            temp = float(0)\n",
    "        defender_temp.append(temp)\n",
    "        if len(defender_temp)/16 == 1:\n",
    "            del defender_temp[12]\n",
    "            del defender_temp[9]\n",
    "            del defender_temp[7]\n",
    "            del defender_temp[5]\n",
    "            tex_def_stats_final.append(defender_temp)\n",
    "            defender_temp = []\n",
    "\n",
    "    tex_def_stats_final = pd.DataFrame(tex_def_stats_final)\n",
    "    tex_def_stats_final.columns = ['LastFirst','Solo','Ast','Tot','TFL,tfl_yds','Sack,sack_yds','FF','FR,fr_yd','Int,int_yds','BrUp','Blkd','QH']\n",
    "\n",
    "    if year_frame == '2018' or year_frame == '2019':\n",
    "        tex_def_stats_final[['Last', 'First']] = tex_def_stats_final['LastFirst'].str.split(' ', n=1, expand=True)\n",
    "    else:\n",
    "        tex_def_stats_final[['Last', 'First']] = tex_def_stats_final['LastFirst'].str.split(',', expand=True)\n",
    "    tex_def_stats_final.drop(columns=['LastFirst'], inplace=True)\n",
    "\n",
    "    tex_def_stats_final[['TFL', 'tfl_yds']] = tex_def_stats_final['TFL,tfl_yds'].str.split('/', expand=True)\n",
    "    tex_def_stats_final.drop(columns=['TFL,tfl_yds'], inplace=True)\n",
    "\n",
    "    tex_def_stats_final[['FR', 'fr_yds']] = tex_def_stats_final['FR,fr_yd'].str.split('/', expand=True)\n",
    "    tex_def_stats_final.drop(columns=['FR,fr_yd'], inplace=True)\n",
    "\n",
    "    tex_def_stats_final[['Sack', 'sack_yds']] = tex_def_stats_final['Sack,sack_yds'].str.split('/', expand=True)\n",
    "    tex_def_stats_final.drop(columns=['Sack,sack_yds'], inplace=True)\n",
    "\n",
    "    tex_def_stats_final['Int'] = float(0)\n",
    "    tex_def_stats_final['int_yds'] = float(0)\n",
    "    for i, value in tex_def_stats_final['Int,int_yds'].items():\n",
    "        if value != 0:\n",
    "            int_lst = value.split('-')\n",
    "\n",
    "            tex_def_stats_final.at[i, 'Int'] = int(int_lst[0])\n",
    "            tex_def_stats_final.at[i, 'int_yds'] = int(int_lst[1])\n",
    "        else:\n",
    "            tex_def_stats_final.at[i, 'Int'] = float(0)\n",
    "            tex_def_stats_final.at[i, 'int_yds'] = float(0)\n",
    "    tex_def_stats_final.drop(columns=['Int,int_yds'], inplace=True)\n",
    "\n",
    "    tex_def_stats_final.replace('-', float(0), inplace=True)\n",
    "\n",
    "    tex_def_stats_final = tex_def_stats_final[['Last','First','Solo','Ast','Tot','TFL','tfl_yds','Sack','sack_yds','FF','FR','fr_yds','Int','int_yds','BrUp','Blkd','QH']]\n",
    "\n",
    "    for i in range(2, len(tex_def_stats_final.columns)):\n",
    "        tex_def_stats_final[tex_def_stats_final.columns[i]] = tex_def_stats_final[tex_def_stats_final.columns[i]].astype(float)\n",
    "\n",
    "    total_row = tex_def_stats_final.select_dtypes(include=float).sum(axis=0)\n",
    "    total_row['Last'] = 'Game'\n",
    "    total_row['First'] = ''\n",
    "    tex_def_stats_final = pd.concat([tex_def_stats_final, total_row.to_frame().T], ignore_index=True) #tex_def_stats_final.append(total_row, ignore_index=True)\n",
    "\n",
    "    return tex_def_stats_final\n",
    "\n",
    "# the only difference btw def scrape 2 and 4 is the tables are 1 off\n",
    "def def_scrape_4(tables, home_team):\n",
    "    if home_team == 'texas':\n",
    "        def_table = tables[33]\n",
    "    else:\n",
    "        def_table = tables[32]\n",
    "\n",
    "    def_2d = []\n",
    "    temp = []\n",
    "    i = 0\n",
    "    for row in def_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            val = val.text.strip()\n",
    "\n",
    "            if i == 1:\n",
    "                if val.find(', ') > -1:\n",
    "                    val = val.split(', ')\n",
    "                    temp.append(val[0])\n",
    "                    temp.append(val[1])\n",
    "                else:\n",
    "                    temp.append(val)\n",
    "                    temp.append('')\n",
    "\n",
    "            elif i == 5 or i == 7 or i == 8 or i == 11:\n",
    "                if val.find('-') > -1:\n",
    "                    val = val.split('-')\n",
    "                    temp.append(val[0])\n",
    "                    temp.append(val[1])\n",
    "                elif val.find('/') > -1:\n",
    "                    val = val.split('/')\n",
    "                    temp.append(val[0])\n",
    "                    temp.append(val[1])\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "                    temp.append(0)\n",
    "            else:\n",
    "                if val == '.':\n",
    "                    val = 0\n",
    "                temp.append(val)\n",
    "            i += 1\n",
    "\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(3, 3 + len(temp[3:])):\n",
    "                if temp[i]:\n",
    "                    temp[i] = float(temp[i])\n",
    "                else:\n",
    "                    temp[i] = 0\n",
    "            def_2d.append(temp)\n",
    "        temp = []\n",
    "        i = 0\n",
    "\n",
    "    if len(def_2d) > 0:\n",
    "            totals = ['GM', 'Game', '']\n",
    "\n",
    "            for j in range(3, 3 + len(def_2d[0][3:])):\n",
    "                total = 0\n",
    "                for i in range(len(def_2d)):\n",
    "                    total += def_2d[i][j]\n",
    "                totals.append(total)\n",
    "            \n",
    "            def_2d.append(totals)\n",
    "\n",
    "    def_col = ['##','Last', 'First','Solo','Ast','Tot','TFL', 'tfl_yds','FF','FR', 'fr_yd','Int','int_yds','BrUp','Blkd','Sack','sack_yds','QH']\n",
    "\n",
    "    def_data = pd.DataFrame(def_2d)\n",
    "    def_data.columns = def_col\n",
    "\n",
    "    return def_data\n",
    "\n",
    "def def_scrape_5(temp, home_team):\n",
    "    # Truncate box score for def stats\n",
    "    def_start = temp.find('## Player               Solo  Ast  Tot  TFL/Yds  FF FR-Yd Intc BrUp Blkd Sack/Yds QH')\n",
    "    if home_team == 'texas':\n",
    "        def_temp = temp[def_start + 10:]\n",
    "        def_start = def_temp.find('## Player               Solo  Ast  Tot  TFL/Yds  FF FR-Yd Intc BrUp Blkd Sack/Yds QH')\n",
    "        def_temp = def_temp[def_start:]\n",
    "    else:\n",
    "        def_temp = temp[def_start:]\n",
    "\n",
    "    # Get def stats\n",
    "    def_stats = []    \n",
    "    line_break = def_temp.find('\\n')\n",
    "    def_temp = def_temp[line_break + 1:]\n",
    "    line_break = def_temp.find('\\n')\n",
    "    header = '## Last  First  Solo  Ast  Tot  TFL tfl_yds  FF FR fr_yd Int int_yds BrUp Blkd Sack sack_yds QH'.split()\n",
    "    # def_stats.append(header)\n",
    "    def_temp = def_temp[line_break:]\n",
    "\n",
    "    line_break = def_temp.find('\\n')\n",
    "    def_temp = def_temp[line_break + 1:]\n",
    "\n",
    "    while True:\n",
    "        line_break = def_temp.find('\\n')\n",
    "        line = def_temp[0:line_break + 1]\n",
    "\n",
    "        if line_break == 1:\n",
    "            break\n",
    "\n",
    "        line = line.replace('--', '-')\n",
    "\n",
    "        game_stat = line.split()\n",
    "\n",
    "        for i in range(len(game_stat)):\n",
    "            if game_stat[i] == '.':\n",
    "                game_stat[i] = ''\n",
    "\n",
    "        try:\n",
    "            first_name_catch = re.search(r',\\s*(.*)$', game_stat[1]).group(1)\n",
    "            if first_name_catch:\n",
    "                last_name_catch = re.search(r'^(.*?),', game_stat[1]).group(1)\n",
    "                game_stat[1] = last_name_catch\n",
    "                game_stat.insert(1, first_name_catch)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if len(game_stat) == 13:\n",
    "            game_stat.insert(2, '')\n",
    "        \n",
    "        if len(game_stat) == 15:\n",
    "            game_stat[2] = str(game_stat[2]) + ' ' + str(game_stat[3])\n",
    "            game_stat.pop(3)\n",
    "\n",
    "        if '/' in game_stat[6]:\n",
    "            parts = game_stat[6].split('/')\n",
    "            game_stat[6:7] = parts\n",
    "        else: \n",
    "            game_stat[6:7] = ['','']\n",
    "\n",
    "        if '/' in game_stat[13]:\n",
    "            parts = game_stat[13].split('/')\n",
    "            game_stat[13:14] = parts\n",
    "        else: \n",
    "            game_stat[13:14] = ['','']\n",
    "        \n",
    "        if '-' in game_stat[9]:\n",
    "            parts = game_stat[9].split('-')\n",
    "            game_stat[9:10] = parts\n",
    "        else: \n",
    "            game_stat[9:10] = ['','']\n",
    "\n",
    "        if '-' in game_stat[11]:\n",
    "            parts = game_stat[11].split('-')\n",
    "            game_stat[11:12] = parts\n",
    "        else: \n",
    "            game_stat[11:12] = ['','']\n",
    "\n",
    "        game_stat[1] = game_stat[1].replace(',', '')\n",
    "        game_stat[2] = game_stat[2].replace(',', '')\n",
    "\n",
    "        for i in range(3, 3 + len(game_stat[3:])):\n",
    "            if game_stat[i]:\n",
    "                game_stat[i] = float(game_stat[i])\n",
    "            else:\n",
    "                game_stat[i] = 0\n",
    "\n",
    "        def_stats.append(game_stat)\n",
    "        def_temp = def_temp[line_break + 1:]\n",
    "\n",
    "    if len(def_stats) > 0:\n",
    "        totals = ['GM', 'Game', '']\n",
    "\n",
    "        for j in range(3, 3 + len(def_stats[0][3:])):\n",
    "            total = 0\n",
    "            for i in range(len(def_stats)):\n",
    "                total += def_stats[i][j]\n",
    "            totals.append(total)\n",
    "        \n",
    "        \n",
    "        def_stats.append(totals)\n",
    "\n",
    "    def_stats = pd.DataFrame(def_stats, columns = header)\n",
    "\n",
    "    return def_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years 1947 - 2007 (excluding the three games in 98) -> stored in master_stats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 60/60 [08:07<00:00,  8.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_1 = pd.DataFrame(stats)\n",
    "\n",
    "defs = {'##' : [], \n",
    "       'Last' : [], \n",
    "       'First' : [], \n",
    "       'Solo' : [], \n",
    "       'Ast' : [], \n",
    "       'Tot' : [], \n",
    "       'TFL' : [], \n",
    "       'tfl_yds' : [], \n",
    "       'FF' : [],\n",
    "       'FR' : [], \n",
    "       'fr_yd' : [], \n",
    "       'Int' : [], \n",
    "       'int_yds' : [], \n",
    "       'BrUp' : [], \n",
    "       'Blkd' : [], \n",
    "       'Sack' : [], \n",
    "       'sack_yds' : [],\n",
    "       'QH' : []\n",
    "}\n",
    "master_def_1 = pd.DataFrame(defs)\n",
    "\n",
    "games = {\n",
    "    'Home Team' : [],\n",
    "    'Away Team'\t: [],\n",
    "    'Home Score' : [],\n",
    "    'Away Score' : [],\n",
    "    'Texas Result' : [],\n",
    "    'Box Score' : []\n",
    "}\n",
    "master_games_1 = pd.DataFrame(games)\n",
    "\n",
    "missed_games_1 = []\n",
    "\n",
    "# get links for each season\n",
    "years_list = [str(47), str(48)]\n",
    "for i in range(50, 100):\n",
    "    years_list.append(str(i))\n",
    "for i in range(0, 8):\n",
    "    years_list.append(f\"{i:02d}\")\n",
    "# years_list.append('08')\n",
    "\n",
    "season_links = []\n",
    "for i in years_list:\n",
    "    season_link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + i + '/teamstat.htm'\n",
    "    season_links.append(season_link)\n",
    "\n",
    "for x in tqdm(range(len(season_links)), desc = \"Database building...\"):\n",
    "    season = season_links[x] # paste specific season link here when troubleshooting\n",
    "    year = years_list[x] # change year manually to when troubleshooting\n",
    "    box_score_links = []\n",
    "\n",
    "    # get season\n",
    "    if int(year) >= 47:\n",
    "        year_frame = '19' + year\n",
    "    else:\n",
    "        year_frame = '20' + year\n",
    "\n",
    "    if year == '98':\n",
    "        box_score_links = ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ucla.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-msu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ksu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ou.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-bu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-nu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-osu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ttu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-tam.htm']\n",
    "    # elif year == '08':\n",
    "    #     # 2008 links\n",
    "    #     box_score_links = ['http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut3.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut4.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut5.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut6.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut7.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut8.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut9.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut10.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut11.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut12.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut13.html']\n",
    "    else:\n",
    "        # open season page\n",
    "        driver.get(season)\n",
    "        texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "        table = texas_sports_soup.find(\"table\")\n",
    "        rows = table.tbody.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            box_score = row.find_all('td')[-1]\n",
    "            try:\n",
    "                link_tail_temp = box_score.font.a['href']\n",
    "                if link_tail_temp == '../../index1919.html':\n",
    "                    missed_games_1.append(row.find_all('td')[-2].get_text())\n",
    "                else:\n",
    "                    built_link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + year + '/' + link_tail_temp\n",
    "                    box_score_links.append(built_link)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # must catch the random 90s TAMU games that are mislinked\n",
    "            if year in [str(91), str(92), str(93), str(95), str(96)]:\n",
    "                box_score_links.append('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + year + '/' + 'UT-A&M.HTM')\n",
    "\n",
    "    for link in box_score_links:\n",
    "        # print(link_tail, year)        \n",
    "        # Get full page soup\n",
    "        # link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/92/ut_nt.htm' # troubleshooting\n",
    "        response = make_request(link)\n",
    "        temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "        if response == '':\n",
    "            driver.get(link)\n",
    "            # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/06/ut11.htm') # for troubleshooting\n",
    "            temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "        temp_text = temp_box_soup.text\n",
    "        temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "        temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "        if year == '06':\n",
    "            # Get away team\n",
    "            away_index = 0\n",
    "            away_endex = temp_text.find(' vs ')\n",
    "            away_team = temp_text[away_index: away_endex].strip().lower()\n",
    "\n",
    "            # Get home team\n",
    "            home_index = temp_text.find(' vs ')\n",
    "            home_endex = temp_text.find(' (')\n",
    "            home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "            # Get game date\n",
    "            date_index = temp_text.find('(')\n",
    "            date_endex = temp_text.find(\")\")\n",
    "            date = temp_text[date_index + 1: date_endex].strip()\n",
    "            date = date.replace(\",\", \"\")\n",
    "            date = date[:-4] + ',' + date[-4:]\n",
    "            date = date.replace(\"Sept\", \"Sep\")\n",
    "            date = date.replace(\" \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "            except ValueError:\n",
    "                date = datetime.strptime(date, \"%b.%d,%Y\")\n",
    "            \n",
    "            # get away score\n",
    "            temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "            temp_text_new = temp_text[temp_index:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            ascore_index = temp_text_new.find(' - ') + 3\n",
    "            ascore_endex = temp_text_new.find('Record: ')\n",
    "            ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "            ascore = float(ascore)\n",
    "\n",
    "            # get home score\n",
    "            temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "            hscore_index = temp_text_new.find(' - ') + 3\n",
    "            hscore_endex = temp_text_new.find('Record: ')\n",
    "            hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "            hscore = float(hscore)\n",
    "            \n",
    "        else:\n",
    "            # Get game date\n",
    "            date_index = temp_text.find('Date: ')\n",
    "            date_endex = temp_text.find(\"Site: \")\n",
    "            date = temp_text[date_index + 6: date_endex].strip()\n",
    "            if date == \"0ct 10, 1959\":\n",
    "                date = \"Oct 10, 1959\"\n",
    "            date = date.replace(\",\", \"\")\n",
    "            date = date[:-4] + ',' + date[-4:]\n",
    "            date = date.replace(\"Sept\", \"Sep\")\n",
    "            date = date.replace(\" \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "            except ValueError:\n",
    "                date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "            # Get away team\n",
    "            away_index = 0\n",
    "            away_endex = temp_text.find(' vs ')\n",
    "            away_team = temp_text[away_index: away_endex].strip().lower()\n",
    "\n",
    "            # Get home team\n",
    "            home_index = temp_text.find(' vs ')\n",
    "            home_endex = temp_text.find(' (')\n",
    "            home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "            # get away score\n",
    "            temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "            temp_text_new = temp_text[temp_index:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            ascore_index = temp_text_new.find(' - ') + 3\n",
    "            ascore_endex = temp_text_new.find('\\n')\n",
    "            ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "            ascore = float(ascore)\n",
    "\n",
    "            # get home score\n",
    "            temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "            hscore_index = temp_text_new.find(' - ') + 3\n",
    "            hscore_endex = temp_text_new.find('\\n')\n",
    "            hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "            hscore = float(hscore)\n",
    "\n",
    "        # did texas win?\n",
    "        if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "            tex_win = \"Win\"\n",
    "        elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "            tex_win = \"Loss\"\n",
    "        else:\n",
    "            tex_win = \"Tie\"\n",
    "\n",
    "        # get UT box score text\n",
    "        temp = temp_box_soup.find('font', string = \"Individual Statistics\")\n",
    "        temp = temp.find_next('font', string = \"Individual Statistics\")\n",
    "        temp = temp.find_next('pre').text\n",
    "        temp = temp.replace('Texas Longhorns', 'Texas')\n",
    "        temp = temp.replace('TEXAS', 'Texas')\n",
    "        start = temp.find('\\nTexas\\n')\n",
    "        temp = temp[start:]\n",
    "        end = temp.find('Punting               No.  Yds   Avg Long In20')\n",
    "        temp = temp[:end]\n",
    "\n",
    "        # Truncate box score for rushing stats\n",
    "        rush_start = temp.find('Rushing              No Gain Loss  Net TD Lg  Avg')\n",
    "        rush_end = temp.find('Passing              ') - 2\n",
    "        rush_temp = temp[rush_start:rush_end]\n",
    "\n",
    "        # Get rushing stats\n",
    "        rush_stats = []    \n",
    "        line_break = rush_temp.find('\\n')\n",
    "        header = rush_temp[0:line_break].split()\n",
    "        rush_stats.append(header)\n",
    "        rush_temp = rush_temp[line_break:]\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        rush_temp = rush_temp[line_break + 1:]\n",
    "\n",
    "        # Now rush temp has no header\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        rush_temp = rush_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = rush_temp.find('\\n')\n",
    "            line = rush_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if rush_temp.find('\\n') == -1:\n",
    "                line = rush_temp\n",
    "                game_stat = line.split()          \n",
    "                rush_stats.append(game_stat)\n",
    "                rush_temp = rush_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 8: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                rush_stats.append(game_stat)\n",
    "                rush_temp = rush_temp[line_break + 1:]\n",
    "        \n",
    "        # Truncate box score for passing stats\n",
    "        pass_start = temp.find('Passing              ')\n",
    "        pass_end = temp.find('Receiving             No.  Yds   TD Long') - 2\n",
    "        pass_temp = temp[pass_start:pass_end]\n",
    "\n",
    "        # Get passing stats\n",
    "        pass_stats = []    \n",
    "        line_break = pass_temp.find('\\n')\n",
    "        header = pass_temp[0:line_break].split()\n",
    "        pass_stats.append(header)\n",
    "        pass_temp = pass_temp[line_break:]\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        pass_temp = pass_temp[line_break + 1:]\n",
    "\n",
    "        # Now pass temp has no header\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        pass_temp = pass_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = pass_temp.find('\\n')\n",
    "            line = pass_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if pass_temp.find('\\n') == -1:\n",
    "                line = pass_temp\n",
    "                game_stat = line.split()\n",
    "                pass_stats.append(game_stat)\n",
    "                pass_temp = pass_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 6: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                pass_stats.append(game_stat)\n",
    "                pass_temp = pass_temp[line_break + 1:]\n",
    "        \n",
    "        # Truncate box score for rec stats\n",
    "        rec_start = temp.find('Receiving             No.  Yds   TD Long')\n",
    "        rec_temp = temp[rec_start:-2]\n",
    "\n",
    "        # Get rec stats\n",
    "        rec_stats = []    \n",
    "        line_break = rec_temp.find('\\n')\n",
    "        header = rec_temp[0:line_break].split()\n",
    "        rec_stats.append(header)\n",
    "        rec_temp = rec_temp[line_break:]\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "        # Now rec temp has no header\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        rec_temp = rec_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = rec_temp.find('\\n')\n",
    "            line = rec_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if rec_temp.find('\\n') == -1:\n",
    "                line = rec_temp\n",
    "                game_stat = line.split()\n",
    "                rec_stats.append(game_stat)\n",
    "                rec_temp = rec_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 5: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                rec_stats.append(game_stat)\n",
    "                rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "        ##############################################################\n",
    "        # Now that we have the stats in 2d lists, we need to make sure they aren't just strings\n",
    "\n",
    "        # First, we must address the formatting of the passing cmp-att-int format\n",
    "        for row in pass_stats:\n",
    "            new_element = row.pop(1).split('-')\n",
    "            row[1:1] = new_element\n",
    "        \n",
    "        # Next, we must make sure the elements are floats and not strings\n",
    "        frames = [pass_stats, rush_stats, rec_stats]\n",
    "        for frame in frames:\n",
    "            for i in range(1,len(frame)):\n",
    "                for j in range(1,len(frame[i])):\n",
    "                    frame[i][j] = float(frame[i][j])\n",
    "                    \n",
    "        # Now, we make the arrays into dataframes using panda\n",
    "        # admittedly i shouldve done this earlier but oh well\n",
    "        rush_data = pd.DataFrame(rush_stats[1:])\n",
    "        rush_data.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "        pass_data = pd.DataFrame(pass_stats[1:])\n",
    "        if 40 < float(year) < 89:\n",
    "            pass_data.columns = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "        else:\n",
    "            pass_data.columns = ['Player', 'Pass Attempts', 'Completions', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "\n",
    "        rec_data = pd.DataFrame(rec_stats[1:])\n",
    "        rec_data.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "        \n",
    "        # Finally, time to merge the data into one full dataframe for the full game\n",
    "        full_game_data = pd.merge(\n",
    "            pass_data, rush_data, how = \"outer\", on = \"Player\"\n",
    "        )\n",
    "        full_game_data = pd.merge(\n",
    "            full_game_data, rec_data, how = 'outer', on = \"Player\"\n",
    "        )\n",
    "        full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "        # small thing but i want to take the ellipsis out of the totals category\n",
    "        full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "        # now make the gameid\n",
    "        gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "        gameid_list = [gameid]\n",
    "\n",
    "        '''\n",
    "        game_df = {'Home Team' : [home_team],\n",
    "                'Away Team' : [away_team],\n",
    "                'Home Score' : [hscore],\n",
    "                'Away Score' : [ascore],\n",
    "                'Texas Result' : [tex_win],\n",
    "                'Box Score' : [full_game_data]\n",
    "                }\n",
    "        \n",
    "        game_df = pd.DataFrame(game_df, index = gameid_list)\n",
    "\n",
    "        # finally append it to the master games\n",
    "        master_games = pd.concat([master_games, game_df], ignore_index = True)\n",
    "\n",
    "        # empty out game_df\n",
    "        game_df = pd.DataFrame()\n",
    "        '''\n",
    "\n",
    "        def_stats = def_scrape_1(temp_box_soup, year)\n",
    "\n",
    "        ##############################################################\n",
    "        # the last thing I want to do is to create one large dataframe with every single game performance ever\n",
    "        # this will contain duplicate players for their different performances in different games\n",
    "        # much less concise, much more usefull (probably)\n",
    "        # first add gameid column\n",
    "        full_game_data['GameID'] = gameid\n",
    "        full_game_data['Date'] = date\n",
    "        full_game_data['Home Team'] = home_team\n",
    "        full_game_data['Away Team'] = away_team\n",
    "        full_game_data['Home Score'] = hscore\n",
    "        full_game_data['Away Score'] = ascore\n",
    "        full_game_data['Texas Result'] = tex_win\n",
    "        full_game_data['Link'] = link\n",
    "        full_game_data['Season'] = year_frame\n",
    "\n",
    "        def_stats['GameID'] = gameid\n",
    "        def_stats['Date'] = date\n",
    "        def_stats['Home Team'] = home_team\n",
    "        def_stats['Away Team'] = away_team\n",
    "        def_stats['Home Score'] = hscore\n",
    "        def_stats['Away Score'] = ascore\n",
    "        def_stats['Texas Result'] = tex_win\n",
    "        def_stats['Link'] = link\n",
    "        def_stats['Season'] = year_frame\n",
    "        \n",
    "        # now add it to the master stats\n",
    "        master_stats_1 = pd.concat([master_stats_1, full_game_data], ignore_index = True)\n",
    "        master_def_1 = pd.concat([master_def_1, def_stats], ignore_index = True)\n",
    "\n",
    "        # finally empty out the full game dataframe\n",
    "        full_game_data = pd.DataFrame() \n",
    "        \n",
    "# print(master_stats_1)\n",
    "master_stats_1.to_csv('master_stats_1.csv', index = False)\n",
    "master_def_1.to_csv('master_def_1.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get stats from blue table style (3 games in 98 and 2009 -2014) \n",
    "note: i have skipped 2008 for the moment, also missing vs arkansas 2014 and vs kansas 2009 vs nebraska 2009\n",
    "-> stored in master_stats_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 69/69 [01:45<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_2 = pd.DataFrame(stats)\n",
    "\n",
    "defs = {'##' : [], \n",
    "       'Last' : [], \n",
    "       'First' : [], \n",
    "       'Solo' : [], \n",
    "       'Ast' : [], \n",
    "       'Tot' : [], \n",
    "       'TFL' : [], \n",
    "       'tfl_yds' : [], \n",
    "       'FF' : [],\n",
    "       'FR' : [], \n",
    "       'fr_yd' : [], \n",
    "       'Int' : [], \n",
    "       'int_yds' : [], \n",
    "       'BrUp' : [], \n",
    "       'Blkd' : [], \n",
    "       'Sack' : [], \n",
    "       'sack_yds' : [],\n",
    "       'QH' : []\n",
    "}\n",
    "master_def_2 = pd.DataFrame(defs)\n",
    "\n",
    "games = {\n",
    "    'Home Team' : [],\n",
    "    'Away Team'\t: [],\n",
    "    'Home Score' : [],\n",
    "    'Away Score' : [],\n",
    "    'Texas Result' : [],\n",
    "    'Box Score' : []\n",
    "}\n",
    "master_games_2 = pd.DataFrame(games)\n",
    "\n",
    "missed_games_2 = []\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "game_links = []\n",
    "# 1998 links\n",
    "rows = table_list[24].tbody.find_all('tr')[2:]\n",
    "for row in rows:\n",
    "    box_score = row.find_all('td')[-1]\n",
    "    try:\n",
    "        link_temp = box_score.a['href']\n",
    "        game_links.append(link_temp)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "game_links = [['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-isu.htm', '1998'],\n",
    "              ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ru.htm', '1998'],\n",
    "              ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-nmsu.htm', '1998']]\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# get most recent year\n",
    "temp = table_list[0].find('td').get_text()\n",
    "year_index = temp.find('\\n')\n",
    "year = temp[year_index - 4:year_index]\n",
    "\n",
    "years_past_2022 = int(year) - 2022\n",
    "\n",
    "game_links = []\n",
    "\n",
    "# links for 2009-2014\n",
    "for table in table_list[8 + years_past_2022 : 14 + years_past_2022]:\n",
    "    row_ind = 3\n",
    "\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    if year == '':\n",
    "        # get year\n",
    "        temp = table.find_all('td')[1].get_text()\n",
    "        year_index = temp.find('\\n')\n",
    "        year = temp[year_index - 4:year_index]\n",
    "        row_ind += 1\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[row_ind:]\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.find_all('a')[1]['href']\n",
    "            game_links.append(list((link_temp, year)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "game_links.remove(['http://texassports.com/boxscore.aspx?path=football&id=8599', '2014'])\n",
    "game_links.remove(['http://stats.texassports.com/sports/m-footbl/2009-2010/ut11.html', '2009'])\n",
    "game_links.remove(['http://stats.texassports.com/sports/m-footbl/2009-2010/big12fb.html', '2009'])\n",
    "\n",
    "for i in tqdm(range(len(game_links)), desc = \"Database building...\"):\n",
    "# for i in range(len(game_links)):\n",
    "    # Get full page soup\n",
    "    link = game_links[i][0]\n",
    "    year = game_links[i][1]\n",
    "\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex - 3].strip()\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    tables = temp_box_soup.find_all(\"table\")\n",
    "    score_table = tables[2]\n",
    "    away_t_row = 1\n",
    "    home_t_row = 2\n",
    "    \n",
    "    away_t_col = 0\n",
    "    home_t_col = 0\n",
    "\n",
    "    away_s_col = 5\n",
    "    home_s_col = 5\n",
    "\n",
    "    home_team = score_table.find_all('tr')[home_t_row].find_all('td')[home_t_col].text.strip().lower()\n",
    "    away_team = score_table.find_all('tr')[away_t_row].find_all('td')[away_t_col].text.strip().lower()\n",
    "    ascore = float(score_table.find_all('tr')[away_t_row].find_all('td')[away_s_col].text.strip())\n",
    "    hscore = float(score_table.find_all('tr')[home_t_row].find_all('td')[home_s_col].text.strip())\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"     \n",
    "\n",
    "    if home_team == 'texas':\n",
    "        rush_table = tables[10]\n",
    "        pass_table = tables[12]\n",
    "        rec_table = tables[14]\n",
    "    else:\n",
    "        rush_table = tables[9]\n",
    "        pass_table = tables[11]\n",
    "        rec_table = tables[13]\n",
    "    \n",
    "    # rush stats\n",
    "    rush_2d = []\n",
    "    temp = []\n",
    "    for row in rush_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rush_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rush_col = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    rush_data = pd.DataFrame(rush_2d)\n",
    "    rush_data.columns = rush_col\n",
    "\n",
    "    # pass stats\n",
    "    pass_2d = []\n",
    "    temp = []\n",
    "    for row in pass_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            pass_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    for row in pass_2d:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "\n",
    "    pass_col = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_2d)\n",
    "    pass_data.columns = pass_col\n",
    "\n",
    "    # pass stats\n",
    "    rec_2d = []\n",
    "    temp = []\n",
    "    for row in rec_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rec_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rec_col = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "            \n",
    "    frames = [pass_2d, rush_2d, rec_2d]\n",
    "    for frame in frames:\n",
    "        for i in range(0,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_2d)\n",
    "    rec_data.columns = rec_col\n",
    "\n",
    "    full_game_data = pd.merge(pass_data, rush_data, how = \"outer\", on = \"Player\")\n",
    "    full_game_data = pd.merge(full_game_data, rec_data, how = 'outer', on = \"Player\")\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    def_stats = def_scrape_2(tables, home_team)\n",
    "\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "    full_game_data['Season'] = year\n",
    "\n",
    "    def_stats['GameID'] = gameid\n",
    "    def_stats['Date'] = date\n",
    "    def_stats['Home Team'] = home_team\n",
    "    def_stats['Away Team'] = away_team\n",
    "    def_stats['Home Score'] = hscore\n",
    "    def_stats['Away Score'] = ascore\n",
    "    def_stats['Texas Result'] = tex_win\n",
    "    def_stats['Link'] = link\n",
    "    def_stats['Season'] = year\n",
    "\n",
    "    master_stats_2 = pd.concat([master_stats_2, full_game_data], ignore_index = True)\n",
    "\n",
    "    master_def_2 = pd.concat([master_def_2, def_stats], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_2.to_csv('master_stats_2.csv', index = False)\n",
    "master_def_2.to_csv('master_def_2.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Links from UT master results (list for post 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "driver.quit()\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# get most recent year\n",
    "temp = table_list[0].find('td').get_text()\n",
    "year_index = temp.find('\\n')\n",
    "year = temp[year_index - 4:year_index]\n",
    "\n",
    "years_past_2022 = int(year) - 2022\n",
    "\n",
    "# link dictionary\n",
    "link_dict = {}\n",
    "for table in table_list[:8 + years_past_2022]:\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[2:]\n",
    "    box_score_links = []\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.a['href']\n",
    "            box_score_links.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    link_dict[year] = box_score_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ut website scrape (2015-2022) missing la tech 2019 (plus http://texassports.com/boxscore.aspx?path=football&id=8599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 114/114 [01:07<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_3 = pd.DataFrame(stats)\n",
    "\n",
    "defs = {'Last' : [], \n",
    "       'First' : [], \n",
    "       'Solo' : [], \n",
    "       'Ast' : [], \n",
    "       'Tot' : [], \n",
    "       'TFL' : [], \n",
    "       'tfl_yds' : [], \n",
    "       'FF' : [],\n",
    "       'FR' : [], \n",
    "       'fr_yds' : [], \n",
    "       'Int' : [], \n",
    "       'int_yds' : [], \n",
    "       'BrUp' : [], \n",
    "       'Blkd' : [], \n",
    "       'Sack' : [], \n",
    "       'sack_yds' : [],\n",
    "       'QH' : []\n",
    "}\n",
    "master_def_3 = pd.DataFrame(defs)\n",
    "\n",
    "# link list\n",
    "links_2015_2022 = []\n",
    "\n",
    "# get most recent year\n",
    "temp = table_list[0].find('td').get_text()\n",
    "year_index = temp.find('\\n')\n",
    "year = temp[year_index - 4:year_index]\n",
    "\n",
    "years_past_2022 = int(year) - 2022\n",
    "\n",
    "for table in table_list[:8 + years_past_2022]:\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[2:]\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.a['href']\n",
    "            links_2015_2022.append([link_temp, year])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# deal with mislinked la tech 2019\n",
    "links_2015_2022[links_2015_2022.index(['hthttps://texassports.com/boxscore.aspx?path=football&id=12601', '2019'])] = ['https://texassports.com/boxscore.aspx?path=football&id=12601', '2019']\n",
    "\n",
    "# texas vs arkansas 2014\n",
    "links_2015_2022.append(['http://texassports.com/boxscore.aspx?path=football&id=8599', '2014'])\n",
    "\n",
    "for i in tqdm(range(len(links_2015_2022)), desc = \"Database building...\"):\n",
    "# for i in range(len(links_2015_2022)):\n",
    "    url = links_2015_2022[i][0]\n",
    "    year_frame = links_2015_2022[i][1]\n",
    "    # driver.get(url)\n",
    "    # driver.implicitly_wait(2) # wait a bit\n",
    "    # page_source = driver.page_source\n",
    "    # soup = BeautifulSoup(page_source)\n",
    "\n",
    "    response = make_request(url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        # print(url)\n",
    "        driver.get(url)\n",
    "        # driver.implicitly_wait(2) # wait a bit\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "\n",
    "    individual_stats = soup.find('section', id='individual-stats')\n",
    "    tables = individual_stats.find_all('table')\n",
    "\n",
    "    score_table = soup.find('table')\n",
    "    score_table = score_table.find_all('td')\n",
    "    for i in range(1, len(score_table)):\n",
    "        try:\n",
    "            x = int(score_table[i+1].text)\n",
    "        except:\n",
    "            ascore = float(score_table[i].text)\n",
    "            home_team = score_table[i+1].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "            break\n",
    "\n",
    "    away_team = score_table[0].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "    hscore = float(score_table[-1].text)\n",
    "\n",
    "    home_team = home_team.replace(\"Winner\", \"\")\n",
    "    away_team = away_team.replace(\"Winner\", \"\")\n",
    "\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get date\n",
    "    big_html = soup.text\n",
    "    date_index = big_html.find('Date:')\n",
    "    date_endex = big_html.find('Site:')\n",
    "    date = big_html[date_index + 6: date_endex].strip()\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "\n",
    "    # make gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "\n",
    "    if home_team == 'texas':\n",
    "        tex_pass = tables[1]\n",
    "        tex_rush = tables[3]\n",
    "        tex_rec = tables[5]\n",
    "    else:\n",
    "        tex_pass = tables[0]\n",
    "        tex_rush = tables[2]\n",
    "        tex_rec = tables[4]\n",
    "\n",
    "    tex_pass_stats = tex_pass.find_all('td')\n",
    "    for i in range(len(tex_pass_stats)):  # convert passers to text\n",
    "        tex_pass_stats[i] = tex_pass_stats[i].text.strip()\n",
    "    passer_temp = []\n",
    "    tex_pass_stats_final = []\n",
    "    for i in range(len(tex_pass_stats)):\n",
    "        passer_temp.append(tex_pass_stats[i])\n",
    "        if len(passer_temp)/8 == 1:\n",
    "            tex_pass_stats_final.append(passer_temp)\n",
    "            passer_temp = []\n",
    "    for i in range(len(tex_pass_stats_final)):\n",
    "        for j in range(1, len(tex_pass_stats_final[i])):\n",
    "            tex_pass_stats_final[i][j] = float(tex_pass_stats_final[i][j])\n",
    "    tex_pass_stats_final = pd.DataFrame(tex_pass_stats_final)\n",
    "    tex_pass_stats_final.columns = ['Player', 'Completions', 'Pass Attempts', 'Pass Yards', 'Passing TDs', 'Interceptions', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    tex_rush_stats = tex_rush.find_all('td')\n",
    "    for i in range(len(tex_rush_stats)):  # convert passers to text\n",
    "        tex_rush_stats[i] = tex_rush_stats[i].text.strip()\n",
    "    rusher_temp = []\n",
    "    tex_rush_stats_final = []\n",
    "    for i in range(len(tex_rush_stats)):\n",
    "        rusher_temp.append(tex_rush_stats[i])\n",
    "        if len(rusher_temp)/8 == 1:\n",
    "            tex_rush_stats_final.append(rusher_temp)\n",
    "            rusher_temp = []\n",
    "    for i in range(len(tex_rush_stats_final)):\n",
    "        for j in range(1, len(tex_rush_stats_final[i])):\n",
    "            tex_rush_stats_final[i][j] = float(tex_rush_stats_final[i][j])\n",
    "    tex_rush_stats_final = pd.DataFrame(tex_rush_stats_final)\n",
    "    tex_rush_stats_final.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    tex_rec_stats = tex_rec.find_all('td')\n",
    "    for i in range(len(tex_rec_stats)):  # convert passers to text\n",
    "        tex_rec_stats[i] = tex_rec_stats[i].text.strip()\n",
    "    recer_temp = []\n",
    "    tex_rec_stats_final = []\n",
    "    for i in range(len(tex_rec_stats)):\n",
    "        recer_temp.append(tex_rec_stats[i])\n",
    "        if len(recer_temp)/5 == 1:\n",
    "            tex_rec_stats_final.append(recer_temp)\n",
    "            recer_temp = []\n",
    "    for i in range(len(tex_rec_stats_final)):\n",
    "        for j in range(1, len(tex_rec_stats_final[i])):\n",
    "            tex_rec_stats_final[i][j] = float(tex_rec_stats_final[i][j])\n",
    "    tex_rec_stats_final = pd.DataFrame(tex_rec_stats_final)\n",
    "    tex_rec_stats_final.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        tex_pass_stats_final, tex_rush_stats_final, how = \"outer\", on = \"Player\")\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        full_game_stats, tex_rec_stats_final, how = 'outer', on = \"Player\")\n",
    "\n",
    "    full_game_stats = full_game_stats.fillna(0)\n",
    "\n",
    "    full_def_stats = def_scrape_3(tables, home_team, year_frame)\n",
    "\n",
    "    full_game_stats['GameID'] = gameid\n",
    "    full_game_stats['Date'] = date\n",
    "    full_game_stats['Home Team'] = home_team\n",
    "    full_game_stats['Away Team'] = away_team\n",
    "    full_game_stats['Home Score'] = hscore\n",
    "    full_game_stats['Away Score'] = ascore\n",
    "    full_game_stats['Texas Result'] = tex_win\n",
    "    full_game_stats['Link'] = url\n",
    "    full_game_stats['Season'] = year_frame\n",
    "\n",
    "    full_def_stats['GameID'] = gameid\n",
    "    full_def_stats['Date'] = date\n",
    "    full_def_stats['Home Team'] = home_team\n",
    "    full_def_stats['Away Team'] = away_team\n",
    "    full_def_stats['Home Score'] = hscore\n",
    "    full_def_stats['Away Score'] = ascore\n",
    "    full_def_stats['Texas Result'] = tex_win\n",
    "    full_def_stats['Link'] = url\n",
    "    full_def_stats['Season'] = year_frame\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_3 = pd.concat([master_stats_3, full_game_stats], ignore_index = True)\n",
    "    master_def_3 = pd.concat([master_def_3, full_def_stats], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_3.to_csv(\"master_stats_3.csv\", index = False)\n",
    "master_def_3.to_csv(\"master_def_3.csv\", index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get glitched blue box scores kansas and nebraska 2009 (probably wouldn't have bothered with these if I knew it was just two games but its nice not to do manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_4 = pd.DataFrame(stats)\n",
    "\n",
    "defs = {'##' : [], \n",
    "       'Last' : [], \n",
    "       'First' : [], \n",
    "       'Solo' : [], \n",
    "       'Ast' : [], \n",
    "       'Tot' : [], \n",
    "       'TFL' : [], \n",
    "       'tfl_yds' : [], \n",
    "       'FF' : [],\n",
    "       'FR' : [], \n",
    "       'fr_yd' : [], \n",
    "       'Int' : [], \n",
    "       'int_yds' : [], \n",
    "       'BrUp' : [], \n",
    "       'Blkd' : [], \n",
    "       'Sack' : [], \n",
    "       'sack_yds' : [],\n",
    "       'QH' : []\n",
    "}\n",
    "master_def_4 = pd.DataFrame(defs)\n",
    "\n",
    "link_list = ['https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/big12fb.html', # nebraska 2009\n",
    "             'https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html'] # kansas 2009\n",
    "\n",
    "for i in tqdm(range(len(link_list)), desc = \"Database building...\"):\n",
    "    link = link_list[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex - 3].strip()\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    tables = temp_box_soup.find_all(\"table\")\n",
    "    score_table = tables[3]\n",
    "    away_t_row = 1\n",
    "    home_t_row = 2\n",
    "\n",
    "    away_t_col = 0\n",
    "    home_t_col = 0\n",
    "\n",
    "    away_s_col = 5\n",
    "    home_s_col = 5\n",
    "\n",
    "    home_team = score_table.find_all('tr')[home_t_row].find_all('td')[home_t_col].text.strip().lower()\n",
    "    away_team = score_table.find_all('tr')[away_t_row].find_all('td')[away_t_col].text.strip().lower()\n",
    "    ascore = float(score_table.find_all('tr')[away_t_row].find_all('td')[away_s_col].text.strip())\n",
    "    hscore = float(score_table.find_all('tr')[home_t_row].find_all('td')[home_s_col].text.strip())\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"     \n",
    "\n",
    "    if home_team == 'texas':\n",
    "        rush_table = tables[11]\n",
    "        pass_table = tables[13]\n",
    "        rec_table = tables[15]\n",
    "    else:\n",
    "        rush_table = tables[10]\n",
    "        pass_table = tables[12]\n",
    "        rec_table = tables[14]\n",
    "\n",
    "    # rush stats\n",
    "    rush_2d = []\n",
    "    temp = []\n",
    "    for row in rush_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rush_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rush_col = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    rush_data = pd.DataFrame(rush_2d)\n",
    "    rush_data.columns = rush_col\n",
    "\n",
    "    # pass stats\n",
    "    pass_2d = []\n",
    "    temp = []\n",
    "    for row in pass_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            pass_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    for row in pass_2d:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "\n",
    "    pass_col = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_2d)\n",
    "    pass_data.columns = pass_col\n",
    "\n",
    "    # pass stats\n",
    "    rec_2d = []\n",
    "    temp = []\n",
    "    for row in rec_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rec_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rec_col = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "            \n",
    "    frames = [pass_2d, rush_2d, rec_2d]\n",
    "    for frame in frames:\n",
    "        for i in range(0,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_2d)\n",
    "    rec_data.columns = rec_col\n",
    "\n",
    "    full_game_data = pd.merge(pass_data, rush_data, how = \"outer\", on = \"Player\")\n",
    "    full_game_data = pd.merge(full_game_data, rec_data, how = 'outer', on = \"Player\")\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    def_game_data = def_scrape_4(tables, home_team)\n",
    "\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "    full_game_data['Season'] = '2009'\n",
    "\n",
    "    def_game_data['GameID'] = gameid\n",
    "    def_game_data['Date'] = date\n",
    "    def_game_data['Home Team'] = home_team\n",
    "    def_game_data['Away Team'] = away_team\n",
    "    def_game_data['Home Score'] = hscore\n",
    "    def_game_data['Away Score'] = ascore\n",
    "    def_game_data['Texas Result'] = tex_win\n",
    "    def_game_data['Link'] = link\n",
    "    def_game_data['Season'] = '2009'\n",
    "\n",
    "    numeric_cols = full_game_data.select_dtypes(include='number').columns\n",
    "    full_game_data[numeric_cols] = full_game_data[numeric_cols].astype(float)\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_4 = pd.concat([master_stats_4, full_game_data], ignore_index = True)\n",
    "    master_def_4 = pd.concat([master_def_4, def_game_data], ignore_index=True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_4.to_csv(\"master_stats_4.csv\", index = False)\n",
    "master_def_4.to_csv(\"master_def_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2008 (i do not like 2008\n",
    "        i do not like it in a gate\n",
    "            i do not like it when it skate\n",
    "                i do not like 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 13/13 [00:11<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_5 = pd.DataFrame(stats)\n",
    "\n",
    "defs = {'##' : [], \n",
    "       'Last' : [], \n",
    "       'First' : [], \n",
    "       'Solo' : [], \n",
    "       'Ast' : [], \n",
    "       'Tot' : [], \n",
    "       'TFL' : [], \n",
    "       'tfl_yds' : [], \n",
    "       'FF' : [],\n",
    "       'FR' : [], \n",
    "       'fr_yd' : [], \n",
    "       'Int' : [], \n",
    "       'int_yds' : [], \n",
    "       'BrUp' : [], \n",
    "       'Blkd' : [], \n",
    "       'Sack' : [], \n",
    "       'sack_yds' : [],\n",
    "       'QH' : []\n",
    "}\n",
    "master_def_5 = pd.DataFrame(defs)\n",
    "\n",
    "link_list = ['http://stats.texassports.com/sports/m-footbl/2008-2009/ut1.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut3.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut4.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut5.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut6.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut7.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut8.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut9.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut10.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut11.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut12.html',            \n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut13.html']\n",
    "\n",
    "for i in tqdm(range(len(link_list)), desc = \"Database building...\"):\n",
    "    # Get full page soup\n",
    "    link = link_list[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/06/ut11.htm') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex].strip()\n",
    "    if date == \"0ct 10, 1959\":\n",
    "        date = \"Oct 10, 1959\"\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    # Get away team\n",
    "    away_index = temp_text.find('Photo Gallery')\n",
    "    away_endex = temp_text.find(' vs ')\n",
    "    away_team = temp_text[away_index + 13: away_endex].strip().lower()\n",
    "    if away_team == \"xas\":\n",
    "        away_team = \"texas\"\n",
    "    elif away_team == \"ylor\":\n",
    "        away_team = \"baylor\"\n",
    "\n",
    "    # Get home team\n",
    "    home_index = temp_text.find(' vs ')\n",
    "    home_endex = temp_text.find(' (')\n",
    "    home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "    # get away score\n",
    "    temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "    temp_text_new = temp_text[temp_index:]\n",
    "    temp_index = temp_text_new.find('\\n')\n",
    "    temp_text_new = temp_text_new[temp_index + 1:]\n",
    "    temp_index = temp_text_new.find('\\n')\n",
    "    temp_text_new = temp_text_new[temp_index + 1:]\n",
    "    ascore_index = temp_text_new.find(' - ') + 3\n",
    "    ascore_endex = temp_text_new.find('\\n')\n",
    "    ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "    ascore = float(ascore)\n",
    "\n",
    "    # get home score\n",
    "    temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "    hscore_index = temp_text_new.find(' - ') + 3\n",
    "    hscore_endex = temp_text_new.find('\\n')\n",
    "    hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "    hscore = float(hscore)\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get UT box score text\n",
    "    temp = temp_box_soup.text\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    temp = temp.replace('Texas Longhorns', 'Texas')\n",
    "    temp = temp.replace('TEXAS', 'Texas')\n",
    "\n",
    "    split = temp.find('Field goal attempts')\n",
    "    if home_team == 'texas': \n",
    "        temp = temp[split:]\n",
    "    else: \n",
    "        temp = temp[:split]\n",
    "\n",
    "    # Truncate box score for rushing stats\n",
    "    rush_start = temp.find('Rushing              No Gain Loss  Net TD Lg  Avg')\n",
    "    rush_end = temp.find('Passing              ') - 2\n",
    "    rush_temp = temp[rush_start:rush_end]\n",
    "\n",
    "    # Get rushing stats\n",
    "    rush_stats = []    \n",
    "    line_break = rush_temp.find('\\n')\n",
    "    header = rush_temp[0:line_break].split()\n",
    "    rush_stats.append(header)\n",
    "    rush_temp = rush_temp[line_break:]\n",
    "    line_break = rush_temp.find('\\n')\n",
    "    rush_temp = rush_temp[line_break + 1:]\n",
    "\n",
    "    # Now rush temp has no header\n",
    "    line_break = rush_temp.find('\\n')\n",
    "    rush_temp = rush_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        line = rush_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if rush_temp.find('\\n') == -1:\n",
    "            line = rush_temp\n",
    "            game_stat = line.split()          \n",
    "            rush_stats.append(game_stat)\n",
    "            rush_temp = rush_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 8: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            rush_stats.append(game_stat)\n",
    "            rush_temp = rush_temp[line_break + 1:]\n",
    "    \n",
    "    # Truncate box score for passing stats\n",
    "    pass_start = temp.find('Passing              ')\n",
    "    pass_end = temp.find('Receiving             No.  Yds   TD Long') - 3\n",
    "    pass_temp = temp[pass_start:pass_end]\n",
    "\n",
    "    # Get passing stats\n",
    "    pass_stats = []    \n",
    "    line_break = pass_temp.find('\\n')\n",
    "    header = pass_temp[0:line_break].split()\n",
    "    pass_stats.append(header)\n",
    "    pass_temp = pass_temp[line_break:]\n",
    "    line_break = pass_temp.find('\\n')\n",
    "    pass_temp = pass_temp[line_break + 1:]\n",
    "\n",
    "    # Now pass temp has no header\n",
    "    line_break = pass_temp.find('\\n')\n",
    "    pass_temp = pass_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        line = pass_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if pass_temp.find('\\n') == -1:\n",
    "            line = pass_temp\n",
    "            game_stat = line.split()\n",
    "            pass_stats.append(game_stat)\n",
    "            pass_temp = pass_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 6: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            pass_stats.append(game_stat)\n",
    "            pass_temp = pass_temp[line_break + 1:]\n",
    "    \n",
    "    # Truncate box score for rec stats\n",
    "    rec_start = temp.find('Receiving             No.  Yds   TD Long')\n",
    "    rec_end = temp.find('Punting               No.  Yds   Avg Long In20   TB')\n",
    "    rec_temp = temp[rec_start:rec_end]\n",
    "\n",
    "    # Get rec stats\n",
    "    rec_stats = []    \n",
    "    line_break = rec_temp.find('\\n')\n",
    "    header = rec_temp[0:line_break].split()\n",
    "    rec_stats.append(header)\n",
    "    rec_temp = rec_temp[line_break:]\n",
    "    line_break = rec_temp.find('\\n')\n",
    "    rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "    # Now rec temp has no header\n",
    "    line_break = rec_temp.find('\\n')\n",
    "    rec_temp = rec_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        line = rec_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if rec_temp.find('\\n') == -1:\n",
    "            line = rec_temp\n",
    "            game_stat = line.split()\n",
    "            rec_stats.append(game_stat)\n",
    "            rec_temp = rec_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 5: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            rec_stats.append(game_stat)\n",
    "            rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "    ##############################################################\n",
    "    # Now that we have the stats in 2d lists, we need to make sure they aren't just strings\n",
    "    # First, we must address the formatting of the passing cmp-att-int format\n",
    "    for row in pass_stats:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "    \n",
    "    # Next, we must make sure the elements are floats and not strings\n",
    "    frames = [pass_stats, rush_stats, rec_stats]\n",
    "    for frame in frames:\n",
    "        for i in range(1,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "                \n",
    "    # Now, we make the arrays into dataframes using panda\n",
    "    # admittedly i shouldve done this earlier but oh well\n",
    "    rush_data = pd.DataFrame(rush_stats[1:])\n",
    "    rush_data.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_stats[1:])\n",
    "    pass_data.columns = ['Player', 'Pass Attempts', 'Completions', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_stats[1:])\n",
    "    rec_data.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "    \n",
    "    # Finally, time to merge the data into one full dataframe for the full game\n",
    "    full_game_data = pd.merge(\n",
    "        pass_data, rush_data, how = \"outer\", on = \"Player\"\n",
    "    )\n",
    "    full_game_data = pd.merge(\n",
    "        full_game_data, rec_data, how = 'outer', on = \"Player\"\n",
    "    )\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    # small thing but i want to take the ellipsis out of the totals category\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    # now make the gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    '''\n",
    "    game_df = {'Home Team' : [home_team],\n",
    "            'Away Team' : [away_team],\n",
    "            'Home Score' : [hscore],\n",
    "            'Away Score' : [ascore],\n",
    "            'Texas Result' : [tex_win],\n",
    "            'Box Score' : [full_game_data]\n",
    "            }\n",
    "    \n",
    "    game_df = pd.DataFrame(game_df, index = gameid_list)\n",
    "\n",
    "    # finally append it to the master games\n",
    "    master_games = pd.concat([master_games, game_df], ignore_index = True)\n",
    "\n",
    "    # empty out game_df\n",
    "    game_df = pd.DataFrame()\n",
    "    '''\n",
    "    temp = temp_box_soup.text\n",
    "    def_game_data = def_scrape_5(temp, home_team)\n",
    "\n",
    "    ##############################################################\n",
    "    # the last thing I want to do is to create one large dataframe with every single game performance ever\n",
    "    # this will contain duplicate players for their different performances in different games\n",
    "    # much less concise, much more usefull (probably)\n",
    "    # first add gameid column\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "    full_game_data['Season'] = '2008'\n",
    "\n",
    "    def_game_data['GameID'] = gameid\n",
    "    def_game_data['Date'] = date\n",
    "    def_game_data['Home Team'] = home_team\n",
    "    def_game_data['Away Team'] = away_team\n",
    "    def_game_data['Home Score'] = hscore\n",
    "    def_game_data['Away Score'] = ascore\n",
    "    def_game_data['Texas Result'] = tex_win\n",
    "    def_game_data['Link'] = link\n",
    "    def_game_data['Season'] = '2008'\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_5 = pd.concat([master_stats_5, full_game_data], ignore_index = True)\n",
    "    master_def_5 = pd.concat([master_def_5, def_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "        \n",
    "# print(master_stats_1)\n",
    "master_stats_5 = master_stats_5[master_stats_5[\"Player\"] != 0]\n",
    "master_stats_5.to_csv('master_stats_5.csv', index = False)\n",
    "master_def_5.to_csv('master_def_5.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023 and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe i can adapt the old code one moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things i need to fix:\n",
    "- north texas glitch [done]\n",
    "- la tech 2019 (maybe this will run now) [done]\n",
    "- 3 games in 1998 [done]\n",
    "- arkansas 2014 [done]\n",
    "- add link to blue tables and new format [done]\n",
    "- 2008, kansas 2009, nebraska 2009 [done]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the master stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_stats_1 = pd.read_csv('master_stats_1.csv')\n",
    "master_stats_2 = pd.read_csv('master_stats_2.csv')\n",
    "master_stats_3 = pd.read_csv('master_stats_3.csv')\n",
    "master_stats_4 = pd.read_csv('master_stats_4.csv')\n",
    "master_stats_5 = pd.read_csv('master_stats_5.csv')\n",
    "\n",
    "master_stats = pd.concat([master_stats_1, \n",
    "                          master_stats_2, \n",
    "                          master_stats_3, \n",
    "                          master_stats_4, \n",
    "                          master_stats_5], \n",
    "                          ignore_index=True)\n",
    "master_stats.to_csv('master_stats.csv', index = False)\n",
    "\n",
    "master_def_1 = pd.read_csv('master_def_1.csv')\n",
    "master_def_2 = pd.read_csv('master_def_2.csv')\n",
    "master_def_3 = pd.read_csv('master_def_3.csv')\n",
    "master_def_4 = pd.read_csv('master_def_4.csv')\n",
    "master_def_5 = pd.read_csv('master_def_5.csv')\n",
    "\n",
    "master_def = pd.concat([master_def_1, \n",
    "                          master_def_2, \n",
    "                          master_def_3, \n",
    "                          master_def_4, \n",
    "                          master_def_5], \n",
    "                          ignore_index=True)\n",
    "master_def.to_csv('master_def.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up\n",
    "- give first and last name columns\n",
    "- strip the names\n",
    "- put names in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_names(row):\n",
    "    full_name = row['Last Name']\n",
    "    if pd.notna(full_name) and pd.isna(row['First Name']):\n",
    "        names = full_name.split()\n",
    "        if len(names) == 2:\n",
    "            row['First Name'] = names[0]\n",
    "            row['Last Name'] = names[1]\n",
    "    return row\n",
    "\n",
    "master_stats_test = pd.read_csv('master_stats.csv')\n",
    "\n",
    "# who the fuck did this to johnny walker 4 times i do not understand\n",
    "master_stats_test['Player'].replace('Walker. Johnny', 'Walker, Johnny', inplace = True)\n",
    "\n",
    "# split on commas\n",
    "master_stats_test[['Last Name', 'First Name']] = master_stats_test['Player'].str.split(pat=',', n=1, expand=True)\n",
    "master_stats_test = master_stats_test.drop('Player', axis=1)\n",
    "\n",
    "# strip the names\n",
    "master_stats_test['Last Name'] = master_stats_test['Last Name'].str.strip()\n",
    "master_stats_test['First Name'] = master_stats_test['First Name'].str.strip()\n",
    "\n",
    "# fix players with \"First Last\" Format\n",
    "master_stats_test = master_stats_test.apply(split_names, axis=1) \n",
    "\n",
    "# order the cols\n",
    "front_columns = ['First Name', 'Last Name']\n",
    "master_stats_test = master_stats_test[front_columns + [col for col in master_stats_test.columns if col not in front_columns]]\n",
    "\n",
    "# change totals to total\n",
    "master_stats_test['Last Name'].replace(\"Total\", \"Game\", inplace = True)\n",
    "master_stats_test['Last Name'].replace(\"Totals\", \"Game\", inplace = True)\n",
    "\n",
    "master_stats_test.drop_duplicates(inplace = True)\n",
    "\n",
    "master_stats_test.to_csv('master_stats_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make player IDs - offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "master_stats_test = pd.read_csv('master_stats_test.csv')\n",
    "\n",
    "# house keeping\n",
    "master_stats_test.loc[master_stats_test['First Name'] == 'Jor', 'First Name'] = 'Jordan'\n",
    "master_stats_test.at[134, 'First Name'] = 'Missing Name'\n",
    "master_stats_test.at[808, 'First Name'] = 'My Main Man'\n",
    "master_stats_test.at[4781, 'First Name'] = 'Missing Name'\n",
    "master_stats_test['First Name'] = master_stats_test['First Name'].replace('Lil\\'J', 'Lil\\'Jordan')\n",
    "\n",
    "master_stats_test['Date'] = pd.to_datetime(master_stats_test['Date'])\n",
    "master_stats_test['Year'] = master_stats_test['Date'].dt.year.astype(int)\n",
    "master_stats_test = master_stats_test.sort_values(by='Date').reset_index(drop=True)\n",
    "master_stats_test['PlayerID'] = ''\n",
    "master_stats_test['NameConcat'] = ''\n",
    "master_stats_test['First Year'] = ''\n",
    "master_stats_test['Last Year'] = ''\n",
    "master_stats_test['Opponent'] = ''\n",
    "master_stats_test['Score'] = master_stats_test['Texas Result'] + ' ' + master_stats_test['Home Score'].astype(int).astype(str) + '-' + master_stats_test['Away Score'].astype(int).astype(str)\n",
    "\n",
    "for i in range(len(master_stats_test)):\n",
    "    if master_stats_test['Home Team'][i] == 'texas':\n",
    "        master_stats_test.loc[i, 'Opponent'] = master_stats_test['Away Team'][i]\n",
    "    else:\n",
    "        master_stats_test.loc[i, 'Opponent'] = master_stats_test['Home Team'][i]\n",
    "\n",
    "# this is a bad bad inefficient piece of code but it adds the concatonated name\n",
    "for i in range(len(master_stats_test)):\n",
    "    try:\n",
    "        float(master_stats_test['First Name'][i])\n",
    "\n",
    "        if master_stats_test['Last Name'][i] == 'Game':\n",
    "            master_stats_test.loc[i, 'NameConcat'] = 'Game'\n",
    "        else:\n",
    "            master_stats_test.loc[i, 'NameConcat'] = 'Team'\n",
    "    except:\n",
    "        master_stats_test.loc[i, 'NameConcat'] = master_stats_test.loc[i, 'First Name'] + master_stats_test.loc[i, 'Last Name']\n",
    "\n",
    "# check if each row is a player or a game, then give the players ids if they don't have them\n",
    "for i in range(len(master_stats_test)):\n",
    "    try:\n",
    "        float(master_stats_test['First Name'][i])\n",
    "        pass\n",
    "    except:\n",
    "        if master_stats_test['PlayerID'][i] == '':\n",
    "            name = master_stats_test['First Name'][i] + master_stats_test['Last Name'][i]\n",
    "            start = master_stats_test['Year'][i] - 1\n",
    "            end = master_stats_test['Year'][i] + 6\n",
    "\n",
    "            conditions = (\n",
    "                (master_stats_test['Year'] < end) &\n",
    "                (master_stats_test['Year'] >= start) &\n",
    "                (master_stats_test['NameConcat'] == name)\n",
    "            )\n",
    "\n",
    "            master_stats_test.loc[conditions, 'PlayerID'] = i + 1\n",
    "            master_stats_test.loc[conditions, 'First Year'] = master_stats_test.loc[conditions, 'Season'].min()\n",
    "            master_stats_test.loc[conditions, 'Last Year'] = master_stats_test.loc[conditions, 'Season'].max()\n",
    "\n",
    "master_stats_test['PlayerID'] = master_stats_test['PlayerID'].astype(str).str.zfill(6)\n",
    "master_stats_test['Fantasy'] = ((-2 * master_stats_test['Interceptions']) + \n",
    "                                (.04 * master_stats_test['Pass Yards']) + \n",
    "                                (6 * master_stats_test['Passing TDs']) + \n",
    "                                (.1 * master_stats_test['Net Rush Yards']) + \n",
    "                                (6 * master_stats_test['Rushing TDs']) + \n",
    "                                (.5 * master_stats_test['Catches']) + \n",
    "                                (.1 * master_stats_test['Receiving Yards']) + \n",
    "                                (6 * master_stats_test['Receiving TDs'])\n",
    ")\n",
    "\n",
    "master_stats_test.to_csv('master_stats_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completions</th>\n",
       "      <th>Pass Attempts</th>\n",
       "      <th>Interceptions</th>\n",
       "      <th>Pass Yards</th>\n",
       "      <th>Passing TDs</th>\n",
       "      <th>Longest Pass</th>\n",
       "      <th>Sacks Taken</th>\n",
       "      <th>Rush Attempts</th>\n",
       "      <th>Rush Yards Gained</th>\n",
       "      <th>Rush Yards Lost</th>\n",
       "      <th>...</th>\n",
       "      <th>Receiving TDs</th>\n",
       "      <th>Longest Reception</th>\n",
       "      <th>Home Score</th>\n",
       "      <th>Away Score</th>\n",
       "      <th>Season</th>\n",
       "      <th>Year</th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>First Year</th>\n",
       "      <th>Last Year</th>\n",
       "      <th>Fantasy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-11-18</th>\n",
       "      <td>38.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>25857</td>\n",
       "      <td>25857</td>\n",
       "      <td>59786</td>\n",
       "      <td>23853.0</td>\n",
       "      <td>23885.0</td>\n",
       "      <td>183.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Completions  Pass Attempts  Interceptions  Pass Yards  \\\n",
       "Date                                                                \n",
       "1989-11-18         38.0           64.0            2.0       482.0   \n",
       "\n",
       "            Passing TDs  Longest Pass  Sacks Taken  Rush Attempts  \\\n",
       "Date                                                                \n",
       "1989-11-18          2.0         105.0          6.0           84.0   \n",
       "\n",
       "            Rush Yards Gained  Rush Yards Lost  ...  Receiving TDs  \\\n",
       "Date                                            ...                  \n",
       "1989-11-18              502.0             72.0  ...            2.0   \n",
       "\n",
       "            Longest Reception  Home Score  Away Score  Season   Year  \\\n",
       "Date                                                                   \n",
       "1989-11-18              175.0       403.0       221.0   25857  25857   \n",
       "\n",
       "            PlayerID  First Year  Last Year  Fantasy  \n",
       "Date                                                  \n",
       "1989-11-18     59786     23853.0    23885.0   183.68  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completions</th>\n",
       "      <th>Pass Attempts</th>\n",
       "      <th>Interceptions</th>\n",
       "      <th>Pass Yards</th>\n",
       "      <th>Passing TDs</th>\n",
       "      <th>Longest Pass</th>\n",
       "      <th>Sacks Taken</th>\n",
       "      <th>Rush Attempts</th>\n",
       "      <th>Rush Yards Gained</th>\n",
       "      <th>Rush Yards Lost</th>\n",
       "      <th>...</th>\n",
       "      <th>Receiving TDs</th>\n",
       "      <th>Longest Reception</th>\n",
       "      <th>Home Score</th>\n",
       "      <th>Away Score</th>\n",
       "      <th>Season</th>\n",
       "      <th>Year</th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>First Year</th>\n",
       "      <th>Last Year</th>\n",
       "      <th>Fantasy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1948-10-23</th>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>23376</td>\n",
       "      <td>23376</td>\n",
       "      <td>575</td>\n",
       "      <td>21420.0</td>\n",
       "      <td>21428.0</td>\n",
       "      <td>116.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-12-17</th>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19600</td>\n",
       "      <td>19600</td>\n",
       "      <td>12363</td>\n",
       "      <td>17632.0</td>\n",
       "      <td>17650.0</td>\n",
       "      <td>58.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-09-27</th>\n",
       "      <td>22.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29700</td>\n",
       "      <td>29700</td>\n",
       "      <td>53047</td>\n",
       "      <td>27704.0</td>\n",
       "      <td>27744.0</td>\n",
       "      <td>185.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-10-11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>17820</td>\n",
       "      <td>17820</td>\n",
       "      <td>29958</td>\n",
       "      <td>15828.0</td>\n",
       "      <td>15847.0</td>\n",
       "      <td>99.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-12-25</th>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>19820</td>\n",
       "      <td>19820</td>\n",
       "      <td>35384</td>\n",
       "      <td>17819.0</td>\n",
       "      <td>17846.0</td>\n",
       "      <td>31.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-11-18</th>\n",
       "      <td>38.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>25857</td>\n",
       "      <td>25857</td>\n",
       "      <td>59786</td>\n",
       "      <td>23853.0</td>\n",
       "      <td>23885.0</td>\n",
       "      <td>183.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-09-10</th>\n",
       "      <td>46.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>23928</td>\n",
       "      <td>23928</td>\n",
       "      <td>61671</td>\n",
       "      <td>21918.0</td>\n",
       "      <td>21940.0</td>\n",
       "      <td>153.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-11-24</th>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>25922</td>\n",
       "      <td>25922</td>\n",
       "      <td>67389</td>\n",
       "      <td>23911.0</td>\n",
       "      <td>23938.0</td>\n",
       "      <td>329.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-07</th>\n",
       "      <td>38.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>19960</td>\n",
       "      <td>19960</td>\n",
       "      <td>53040</td>\n",
       "      <td>17953.0</td>\n",
       "      <td>17971.0</td>\n",
       "      <td>199.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Completions  Pass Attempts  Interceptions  Pass Yards  \\\n",
       "Date                                                                \n",
       "1948-10-23         12.0           32.0            2.0       246.0   \n",
       "1960-12-17         14.0           34.0            2.0       236.0   \n",
       "1980-09-27         22.0           42.0            2.0       348.0   \n",
       "1980-10-11         12.0           34.0            4.0       198.0   \n",
       "1982-12-25         12.0           46.0            2.0       100.0   \n",
       "1989-11-18         38.0           64.0            2.0       482.0   \n",
       "1994-09-10         46.0           76.0            4.0       494.0   \n",
       "1994-11-24         38.0           54.0            0.0       608.0   \n",
       "1996-12-07         38.0           58.0            4.0       706.0   \n",
       "\n",
       "            Passing TDs  Longest Pass  Sacks Taken  Rush Attempts  \\\n",
       "Date                                                                \n",
       "1948-10-23          2.0           0.0          0.0           86.0   \n",
       "1960-12-17          0.0           0.0          0.0           90.0   \n",
       "1980-09-27          2.0          75.0          0.0          104.0   \n",
       "1980-10-11          0.0          50.0          0.0          132.0   \n",
       "1982-12-25          0.0          28.0          0.0           88.0   \n",
       "1989-11-18          2.0         105.0          6.0           84.0   \n",
       "1994-09-10          2.0          88.0          0.0           76.0   \n",
       "1994-11-24         10.0         105.0          0.0           88.0   \n",
       "1996-12-07          2.0         132.0          0.0           56.0   \n",
       "\n",
       "            Rush Yards Gained  Rush Yards Lost  ...  Receiving TDs  \\\n",
       "Date                                            ...                  \n",
       "1948-10-23              374.0             58.0  ...            2.0   \n",
       "1960-12-17              270.0             22.0  ...            0.0   \n",
       "1980-09-27              610.0             26.0  ...            2.0   \n",
       "1980-10-11              522.0             24.0  ...            0.0   \n",
       "1982-12-25              274.0            114.0  ...            0.0   \n",
       "1989-11-18              502.0             72.0  ...            2.0   \n",
       "1994-09-10              370.0             62.0  ...            2.0   \n",
       "1994-11-24              576.0             20.0  ...           10.0   \n",
       "1996-12-07              330.0             30.0  ...            2.0   \n",
       "\n",
       "            Longest Reception  Home Score  Away Score  Season   Year  \\\n",
       "Date                                                                   \n",
       "1948-10-23              181.0        84.0       240.0   23376  23376   \n",
       "1960-12-17              105.0        30.0        30.0   19600  19600   \n",
       "1980-09-27              158.0       525.0         0.0   29700  29700   \n",
       "1980-10-11              107.0       117.0       180.0   17820  17820   \n",
       "1982-12-25               56.0       100.0       260.0   19820  19820   \n",
       "1989-11-18              175.0       403.0       221.0   25857  25857   \n",
       "1994-09-10              192.0       360.0       192.0   23928  23928   \n",
       "1994-11-24              203.0       455.0       819.0   25922  25922   \n",
       "1996-12-07              290.0       370.0       270.0   19960  19960   \n",
       "\n",
       "            PlayerID  First Year  Last Year  Fantasy  \n",
       "Date                                                  \n",
       "1948-10-23       575     21420.0    21428.0   116.24  \n",
       "1960-12-17     12363     17632.0    17650.0    58.84  \n",
       "1980-09-27     53047     27704.0    27744.0   185.92  \n",
       "1980-10-11     29958     15828.0    15847.0    99.72  \n",
       "1982-12-25     35384     17819.0    17846.0    31.80  \n",
       "1989-11-18     59786     23853.0    23885.0   183.68  \n",
       "1994-09-10     61671     21918.0    21940.0   153.36  \n",
       "1994-11-24     67389     23911.0    23938.0   329.72  \n",
       "1996-12-07     53040     17953.0    17971.0   199.24  \n",
       "\n",
       "[9 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = pd.read_csv('master_stats_final.csv')\n",
    "\n",
    "x = x.groupby('Date').sum(numeric_only=True)\n",
    "y = x[x['Completions'] != x['Catches']]\n",
    "display(y)\n",
    "\n",
    "z = x[x['Pass Yards'] != x['Receiving Yards']]\n",
    "display(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
