{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(matrix):\n",
    "    for row in matrix:\n",
    "        for element in row:\n",
    "            print(element, end='\\t')  # Separate elements by a tab (or any delimiter you prefer)\n",
    "        print()  # Move to the next line for the next row\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def modern_style_scrape(link):\n",
    "    response = make_request(link)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        # print(link)\n",
    "        driver.get(link)\n",
    "        # driver.implicitly_wait(2) # wait a bit\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "        driver.quit()\n",
    "\n",
    "    individual_stats = soup.find('section', id='individual-stats')\n",
    "    tables = individual_stats.find_all('table')\n",
    "\n",
    "    score_table = soup.find('table')\n",
    "    score_table = score_table.find_all('td')\n",
    "    for i in range(1, len(score_table)):\n",
    "        try:\n",
    "            x = int(score_table[i+1].text)\n",
    "        except:\n",
    "            ascore = float(score_table[i].text)\n",
    "            home_team = score_table[i+1].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "            break\n",
    "\n",
    "    away_team = score_table[0].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "    hscore = float(score_table[-1].text)\n",
    "\n",
    "    home_team = home_team.replace(\"Winner\", \"\")\n",
    "    away_team = away_team.replace(\"Winner\", \"\")\n",
    "\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get date\n",
    "    big_html = soup.text\n",
    "    date_index = big_html.find('Date:')\n",
    "    date_endex = big_html.find('Site:')\n",
    "    date = big_html[date_index + 6: date_endex].strip()\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "\n",
    "    # make gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "\n",
    "    if home_team == 'texas':\n",
    "        tex_pass = tables[1]\n",
    "        tex_rush = tables[3]\n",
    "        tex_rec = tables[5]\n",
    "    else:\n",
    "        tex_pass = tables[0]\n",
    "        tex_rush = tables[2]\n",
    "        tex_rec = tables[4]\n",
    "\n",
    "    tex_pass_stats = tex_pass.find_all('td')\n",
    "    for i in range(len(tex_pass_stats)):  # convert passers to text\n",
    "        tex_pass_stats[i] = tex_pass_stats[i].text.strip()\n",
    "    passer_temp = []\n",
    "    tex_pass_stats_final = []\n",
    "    for i in range(len(tex_pass_stats)):\n",
    "        passer_temp.append(tex_pass_stats[i])\n",
    "        if len(passer_temp)/8 == 1:\n",
    "            tex_pass_stats_final.append(passer_temp)\n",
    "            passer_temp = []\n",
    "    for i in range(len(tex_pass_stats_final)):\n",
    "        for j in range(1, len(tex_pass_stats_final[i])):\n",
    "            tex_pass_stats_final[i][j] = float(tex_pass_stats_final[i][j])\n",
    "    tex_pass_stats_final = pd.DataFrame(tex_pass_stats_final)\n",
    "    tex_pass_stats_final.columns = ['Player', 'Completions', 'Pass Attempts', 'Pass Yards', 'Passing TDs', 'Interceptions', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    tex_rush_stats = tex_rush.find_all('td')\n",
    "    for i in range(len(tex_rush_stats)):  # convert passers to text\n",
    "        tex_rush_stats[i] = tex_rush_stats[i].text.strip()\n",
    "    rusher_temp = []\n",
    "    tex_rush_stats_final = []\n",
    "    for i in range(len(tex_rush_stats)):\n",
    "        rusher_temp.append(tex_rush_stats[i])\n",
    "        if len(rusher_temp)/8 == 1:\n",
    "            tex_rush_stats_final.append(rusher_temp)\n",
    "            rusher_temp = []\n",
    "    for i in range(len(tex_rush_stats_final)):\n",
    "        for j in range(1, len(tex_rush_stats_final[i])):\n",
    "            tex_rush_stats_final[i][j] = float(tex_rush_stats_final[i][j])\n",
    "    tex_rush_stats_final = pd.DataFrame(tex_rush_stats_final)\n",
    "    tex_rush_stats_final.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    tex_rec_stats = tex_rec.find_all('td')\n",
    "    for i in range(len(tex_rec_stats)):  # convert passers to text\n",
    "        tex_rec_stats[i] = tex_rec_stats[i].text.strip()\n",
    "    recer_temp = []\n",
    "    tex_rec_stats_final = []\n",
    "    for i in range(len(tex_rec_stats)):\n",
    "        recer_temp.append(tex_rec_stats[i])\n",
    "        if len(recer_temp)/5 == 1:\n",
    "            tex_rec_stats_final.append(recer_temp)\n",
    "            recer_temp = []\n",
    "    for i in range(len(tex_rec_stats_final)):\n",
    "        for j in range(1, len(tex_rec_stats_final[i])):\n",
    "            tex_rec_stats_final[i][j] = float(tex_rec_stats_final[i][j])\n",
    "    tex_rec_stats_final = pd.DataFrame(tex_rec_stats_final)\n",
    "    tex_rec_stats_final.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        tex_pass_stats_final, tex_rush_stats_final, how = \"outer\", on = \"Player\")\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        full_game_stats, tex_rec_stats_final, how = 'outer', on = \"Player\")\n",
    "\n",
    "    full_game_stats = full_game_stats.fillna(0)\n",
    "\n",
    "    full_game_stats['GameID'] = gameid\n",
    "    full_game_stats['Date'] = date\n",
    "    full_game_stats['Home Team'] = home_team\n",
    "    full_game_stats['Away Team'] = away_team\n",
    "    full_game_stats['Home Score'] = hscore\n",
    "    full_game_stats['Away Score'] = ascore\n",
    "    full_game_stats['Texas Result'] = tex_win\n",
    "    full_game_stats['Link'] = link\n",
    "\n",
    "    return full_game_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years 1947 - 2007 (excluding the three games in 98) -> stored in master_stats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 60/60 [03:13<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_1 = pd.DataFrame(stats)\n",
    "\n",
    "games = {\n",
    "    'Home Team' : [],\n",
    "    'Away Team'\t: [],\n",
    "    'Home Score' : [],\n",
    "    'Away Score' : [],\n",
    "    'Texas Result' : [],\n",
    "    'Box Score' : []\n",
    "}\n",
    "master_games_1 = pd.DataFrame(games)\n",
    "\n",
    "missed_games_1 = []\n",
    "\n",
    "# get links for each season\n",
    "years_list = [str(47), str(48)]\n",
    "for i in range(50, 100):\n",
    "    years_list.append(str(i))\n",
    "for i in range(0, 8):\n",
    "    years_list.append(f\"{i:02d}\")\n",
    "# years_list.append('08')\n",
    "\n",
    "season_links = []\n",
    "for i in years_list:\n",
    "    season_link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + i + '/teamstat.htm'\n",
    "    season_links.append(season_link)\n",
    "\n",
    "for x in tqdm(range(len(season_links)), desc = \"Database building...\"):\n",
    "    season = season_links[x] # paste specific season link here when troubleshooting\n",
    "    year = years_list[x] # change year manually to when troubleshooting\n",
    "    box_score_links = []\n",
    "    if year == '98':\n",
    "        box_score_links = ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ucla.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-msu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ksu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ou.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-bu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-nu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-osu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ttu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-tam.htm']\n",
    "    # elif year == '08':\n",
    "    #     # 2008 links\n",
    "    #     box_score_links = ['http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut3.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut4.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut5.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut6.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut7.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut8.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut9.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut10.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut11.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut12.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut13.html']\n",
    "    else:\n",
    "        # open season page\n",
    "        driver.get(season)\n",
    "        texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "        table = texas_sports_soup.find(\"table\")\n",
    "        rows = table.tbody.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            box_score = row.find_all('td')[-1]\n",
    "            try:\n",
    "                link_tail_temp = box_score.font.a['href']\n",
    "                if link_tail_temp == '../../index1919.html':\n",
    "                    missed_games_1.append(row.find_all('td')[-2].get_text())\n",
    "                else:\n",
    "                    built_link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + year + '/' + link_tail_temp\n",
    "                    box_score_links.append(built_link)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # must catch the random 90s TAMU games that are mislinked\n",
    "            if year in [str(91), str(92), str(93), str(95), str(96)]:\n",
    "                box_score_links.append('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + year + '/' + 'UT-A&M.HTM')\n",
    "\n",
    "    for link in box_score_links:\n",
    "        # print(link_tail, year)        \n",
    "        # Get full page soup\n",
    "        # link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/92/ut_nt.htm' # troubleshooting\n",
    "        response = make_request(link)\n",
    "        temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "        if response == '':\n",
    "            driver.get(link)\n",
    "            # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/06/ut11.htm') # for troubleshooting\n",
    "            temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "        temp_text = temp_box_soup.text\n",
    "        temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "        temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "        if year == '06':\n",
    "            # Get away team\n",
    "            away_index = 0\n",
    "            away_endex = temp_text.find(' vs ')\n",
    "            away_team = temp_text[away_index: away_endex].strip().lower()\n",
    "\n",
    "            # Get home team\n",
    "            home_index = temp_text.find(' vs ')\n",
    "            home_endex = temp_text.find(' (')\n",
    "            home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "            # Get game date\n",
    "            date_index = temp_text.find('(')\n",
    "            date_endex = temp_text.find(\")\")\n",
    "            date = temp_text[date_index + 1: date_endex].strip()\n",
    "            date = date.replace(\",\", \"\")\n",
    "            date = date[:-4] + ',' + date[-4:]\n",
    "            date = date.replace(\"Sept\", \"Sep\")\n",
    "            date = date.replace(\" \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "            except ValueError:\n",
    "                date = datetime.strptime(date, \"%b.%d,%Y\")\n",
    "            \n",
    "            # get away score\n",
    "            temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "            temp_text_new = temp_text[temp_index:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            ascore_index = temp_text_new.find(' - ') + 3\n",
    "            ascore_endex = temp_text_new.find('Record: ')\n",
    "            ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "            ascore = float(ascore)\n",
    "\n",
    "            # get home score\n",
    "            temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "            hscore_index = temp_text_new.find(' - ') + 3\n",
    "            hscore_endex = temp_text_new.find('Record: ')\n",
    "            hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "            hscore = float(hscore)\n",
    "            \n",
    "        else:\n",
    "            # Get game date\n",
    "            date_index = temp_text.find('Date: ')\n",
    "            date_endex = temp_text.find(\"Site: \")\n",
    "            date = temp_text[date_index + 6: date_endex].strip()\n",
    "            if date == \"0ct 10, 1959\":\n",
    "                date = \"Oct 10, 1959\"\n",
    "            date = date.replace(\",\", \"\")\n",
    "            date = date[:-4] + ',' + date[-4:]\n",
    "            date = date.replace(\"Sept\", \"Sep\")\n",
    "            date = date.replace(\" \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "            except ValueError:\n",
    "                date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "            # Get away team\n",
    "            away_index = 0\n",
    "            away_endex = temp_text.find(' vs ')\n",
    "            away_team = temp_text[away_index: away_endex].strip().lower()\n",
    "\n",
    "            # Get home team\n",
    "            home_index = temp_text.find(' vs ')\n",
    "            home_endex = temp_text.find(' (')\n",
    "            home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "            # get away score\n",
    "            temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "            temp_text_new = temp_text[temp_index:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            ascore_index = temp_text_new.find(' - ') + 3\n",
    "            ascore_endex = temp_text_new.find('\\n')\n",
    "            ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "            ascore = float(ascore)\n",
    "\n",
    "            # get home score\n",
    "            temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "            hscore_index = temp_text_new.find(' - ') + 3\n",
    "            hscore_endex = temp_text_new.find('\\n')\n",
    "            hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "            hscore = float(hscore)\n",
    "\n",
    "        # did texas win?\n",
    "        if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "            tex_win = \"Win\"\n",
    "        elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "            tex_win = \"Loss\"\n",
    "        else:\n",
    "            tex_win = \"Tie\"\n",
    "\n",
    "        # get UT box score text\n",
    "        temp = temp_box_soup.find('font', string = \"Individual Statistics\")\n",
    "        temp = temp.find_next('font', string = \"Individual Statistics\")\n",
    "        temp = temp.find_next('pre').text\n",
    "        temp = temp.replace('Texas Longhorns', 'Texas')\n",
    "        temp = temp.replace('TEXAS', 'Texas')\n",
    "        start = temp.find('\\nTexas\\n')\n",
    "        temp = temp[start:]\n",
    "        end = temp.find('Punting               No.  Yds   Avg Long In20')\n",
    "        temp = temp[:end]\n",
    "\n",
    "        # Truncate box score for rushing stats\n",
    "        rush_start = temp.find('Rushing              No Gain Loss  Net TD Lg  Avg')\n",
    "        rush_end = temp.find('Passing              ') - 2\n",
    "        rush_temp = temp[rush_start:rush_end]\n",
    "\n",
    "        # Get rushing stats\n",
    "        rush_stats = []    \n",
    "        line_break = rush_temp.find('\\n')\n",
    "        header = rush_temp[0:line_break].split()\n",
    "        rush_stats.append(header)\n",
    "        rush_temp = rush_temp[line_break:]\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        rush_temp = rush_temp[line_break + 1:]\n",
    "\n",
    "        # Now rush temp has no header\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        rush_temp = rush_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = rush_temp.find('\\n')\n",
    "            line = rush_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if rush_temp.find('\\n') == -1:\n",
    "                line = rush_temp\n",
    "                game_stat = line.split()          \n",
    "                rush_stats.append(game_stat)\n",
    "                rush_temp = rush_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 8: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                rush_stats.append(game_stat)\n",
    "                rush_temp = rush_temp[line_break + 1:]\n",
    "        \n",
    "        # Truncate box score for passing stats\n",
    "        pass_start = temp.find('Passing              ')\n",
    "        pass_end = temp.find('Receiving             No.  Yds   TD Long') - 2\n",
    "        pass_temp = temp[pass_start:pass_end]\n",
    "\n",
    "        # Get passing stats\n",
    "        pass_stats = []    \n",
    "        line_break = pass_temp.find('\\n')\n",
    "        header = pass_temp[0:line_break].split()\n",
    "        pass_stats.append(header)\n",
    "        pass_temp = pass_temp[line_break:]\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        pass_temp = pass_temp[line_break + 1:]\n",
    "\n",
    "        # Now pass temp has no header\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        pass_temp = pass_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = pass_temp.find('\\n')\n",
    "            line = pass_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if pass_temp.find('\\n') == -1:\n",
    "                line = pass_temp\n",
    "                game_stat = line.split()\n",
    "                pass_stats.append(game_stat)\n",
    "                pass_temp = pass_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 6: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                pass_stats.append(game_stat)\n",
    "                pass_temp = pass_temp[line_break + 1:]\n",
    "        \n",
    "        # Truncate box score for rec stats\n",
    "        rec_start = temp.find('Receiving             No.  Yds   TD Long')\n",
    "        rec_temp = temp[rec_start:-2]\n",
    "\n",
    "        # Get rec stats\n",
    "        rec_stats = []    \n",
    "        line_break = rec_temp.find('\\n')\n",
    "        header = rec_temp[0:line_break].split()\n",
    "        rec_stats.append(header)\n",
    "        rec_temp = rec_temp[line_break:]\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "        # Now rec temp has no header\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        rec_temp = rec_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = rec_temp.find('\\n')\n",
    "            line = rec_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if rec_temp.find('\\n') == -1:\n",
    "                line = rec_temp\n",
    "                game_stat = line.split()\n",
    "                rec_stats.append(game_stat)\n",
    "                rec_temp = rec_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 5: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                rec_stats.append(game_stat)\n",
    "                rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "        ##############################################################\n",
    "        # Now that we have the stats in 2d lists, we need to make sure they aren't just strings\n",
    "\n",
    "        # First, we must address the formatting of the passing cmp-att-int format\n",
    "        for row in pass_stats:\n",
    "            new_element = row.pop(1).split('-')\n",
    "            row[1:1] = new_element\n",
    "        \n",
    "        # Next, we must make sure the elements are floats and not strings\n",
    "        frames = [pass_stats, rush_stats, rec_stats]\n",
    "        for frame in frames:\n",
    "            for i in range(1,len(frame)):\n",
    "                for j in range(1,len(frame[i])):\n",
    "                    frame[i][j] = float(frame[i][j])\n",
    "                    \n",
    "        # Now, we make the arrays into dataframes using panda\n",
    "        # admittedly i shouldve done this earlier but oh well\n",
    "        rush_data = pd.DataFrame(rush_stats[1:])\n",
    "        rush_data.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "        pass_data = pd.DataFrame(pass_stats[1:])\n",
    "        if 40 < float(year) < 89:\n",
    "            pass_data.columns = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "        else:\n",
    "            pass_data.columns = ['Player', 'Pass Attempts', 'Completions', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "\n",
    "        rec_data = pd.DataFrame(rec_stats[1:])\n",
    "        rec_data.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "        \n",
    "        # Finally, time to merge the data into one full dataframe for the full game\n",
    "        full_game_data = pd.merge(\n",
    "            pass_data, rush_data, how = \"outer\", on = \"Player\"\n",
    "        )\n",
    "        full_game_data = pd.merge(\n",
    "            full_game_data, rec_data, how = 'outer', on = \"Player\"\n",
    "        )\n",
    "        full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "        # small thing but i want to take the ellipsis out of the totals category\n",
    "        full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "        # now make the gameid\n",
    "        gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "        gameid_list = [gameid]\n",
    "\n",
    "        '''\n",
    "        game_df = {'Home Team' : [home_team],\n",
    "                'Away Team' : [away_team],\n",
    "                'Home Score' : [hscore],\n",
    "                'Away Score' : [ascore],\n",
    "                'Texas Result' : [tex_win],\n",
    "                'Box Score' : [full_game_data]\n",
    "                }\n",
    "        \n",
    "        game_df = pd.DataFrame(game_df, index = gameid_list)\n",
    "\n",
    "        # finally append it to the master games\n",
    "        master_games = pd.concat([master_games, game_df], ignore_index = True)\n",
    "\n",
    "        # empty out game_df\n",
    "        game_df = pd.DataFrame()\n",
    "        '''\n",
    "\n",
    "        ##############################################################\n",
    "        # the last thing I want to do is to create one large dataframe with every single game performance ever\n",
    "        # this will contain duplicate players for their different performances in different games\n",
    "        # much less concise, much more usefull (probably)\n",
    "        # first add gameid column\n",
    "        full_game_data['GameID'] = gameid\n",
    "        full_game_data['Date'] = date\n",
    "        full_game_data['Home Team'] = home_team\n",
    "        full_game_data['Away Team'] = away_team\n",
    "        full_game_data['Home Score'] = hscore\n",
    "        full_game_data['Away Score'] = ascore\n",
    "        full_game_data['Texas Result'] = tex_win\n",
    "        full_game_data['Link'] = link\n",
    "        \n",
    "        # now add it to the master stats\n",
    "        master_stats_1 = pd.concat([master_stats_1, full_game_data], ignore_index = True)\n",
    "\n",
    "        # finally empty out the full game dataframe\n",
    "        full_game_data = pd.DataFrame() \n",
    "        \n",
    "# print(master_stats_1)\n",
    "master_stats_1.to_csv('master_stats_1.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get stats from blue table style (3 games in 98 and 2009 -2014) \n",
    "note: i have skipped 2008 for the moment, also missing vs arkansas 2014 and vs kansas 2009 vs nebraska 2009\n",
    "-> stored in master_stats_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 73/73 [01:05<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_2 = pd.DataFrame(stats)\n",
    "\n",
    "games = {\n",
    "    'Home Team' : [],\n",
    "    'Away Team'\t: [],\n",
    "    'Home Score' : [],\n",
    "    'Away Score' : [],\n",
    "    'Texas Result' : [],\n",
    "    'Box Score' : []\n",
    "}\n",
    "master_games_2 = pd.DataFrame(games)\n",
    "\n",
    "missed_games_2 = []\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "game_links = []\n",
    "# 1998 links\n",
    "rows = table_list[24].tbody.find_all('tr')[2:]\n",
    "for row in rows:\n",
    "    box_score = row.find_all('td')[-1]\n",
    "    try:\n",
    "        link_temp = box_score.a['href']\n",
    "        game_links.append(link_temp)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "game_links = ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-isu.htm',\n",
    "              'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ru.htm',\n",
    "              'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-nmsu.htm']\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# links for 2009-2014\n",
    "for table in table_list[8:14]:\n",
    "    # get year\n",
    "    # temp = table.find('td').get_text()\n",
    "    # year_index = temp.find('\\n')\n",
    "    # year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[3:]\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.find_all('a')[1]['href']\n",
    "            game_links.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "game_links.remove('http://texassports.com/boxscore.aspx?path=football&id=8599')\n",
    "game_links.remove('http://stats.texassports.com/sports/m-footbl/2009-2010/ut11.html')\n",
    "game_links.remove('http://stats.texassports.com/sports/m-footbl/2009-2010/big12fb.html')\n",
    "\n",
    "for i in tqdm(range(len(game_links)), desc = \"Database building...\"):\n",
    "# for i in range(len(game_links)):\n",
    "    # Get full page soup\n",
    "    link = game_links[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex - 3].strip()\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    tables = temp_box_soup.find_all(\"table\")\n",
    "    score_table = tables[2]\n",
    "    away_t_row = 1\n",
    "    home_t_row = 2\n",
    "    \n",
    "    away_t_col = 0\n",
    "    home_t_col = 0\n",
    "\n",
    "    away_s_col = 5\n",
    "    home_s_col = 5\n",
    "\n",
    "    home_team = score_table.find_all('tr')[home_t_row].find_all('td')[home_t_col].text.strip().lower()\n",
    "    away_team = score_table.find_all('tr')[away_t_row].find_all('td')[away_t_col].text.strip().lower()\n",
    "    ascore = float(score_table.find_all('tr')[away_t_row].find_all('td')[away_s_col].text.strip())\n",
    "    hscore = float(score_table.find_all('tr')[home_t_row].find_all('td')[home_s_col].text.strip())\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"     \n",
    "\n",
    "    if home_team == 'texas':\n",
    "        rush_table = tables[10]\n",
    "        pass_table = tables[12]\n",
    "        rec_table = tables[14]\n",
    "    else:\n",
    "        rush_table = tables[9]\n",
    "        pass_table = tables[11]\n",
    "        rec_table = tables[13]\n",
    "    \n",
    "    # rush stats\n",
    "    rush_2d = []\n",
    "    temp = []\n",
    "    for row in rush_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rush_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rush_col = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    rush_data = pd.DataFrame(rush_2d)\n",
    "    rush_data.columns = rush_col\n",
    "\n",
    "    # pass stats\n",
    "    pass_2d = []\n",
    "    temp = []\n",
    "    for row in pass_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            pass_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    for row in pass_2d:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "\n",
    "    pass_col = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_2d)\n",
    "    pass_data.columns = pass_col\n",
    "\n",
    "    # pass stats\n",
    "    rec_2d = []\n",
    "    temp = []\n",
    "    for row in rec_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rec_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rec_col = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "            \n",
    "    frames = [pass_2d, rush_2d, rec_2d]\n",
    "    for frame in frames:\n",
    "        for i in range(0,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_2d)\n",
    "    rec_data.columns = rec_col\n",
    "\n",
    "    full_game_data = pd.merge(pass_data, rush_data, how = \"outer\", on = \"Player\")\n",
    "    full_game_data = pd.merge(full_game_data, rec_data, how = 'outer', on = \"Player\")\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "\n",
    "    master_stats_2 = pd.concat([master_stats_2, full_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_2.to_csv('master_stats_2.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Links from UT master results (list for post 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "driver.quit()\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# link dictionary\n",
    "link_dict = {}\n",
    "for table in table_list[:8]:\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[2:]\n",
    "    box_score_links = []\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.a['href']\n",
    "            box_score_links.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    link_dict[year] = box_score_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ut website scrape (2015-2022) missing la tech 2019 (plus http://texassports.com/boxscore.aspx?path=football&id=8599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 100/100 [03:13<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_3 = pd.DataFrame(stats)\n",
    "\n",
    "# link dictionary\n",
    "links_2015_2022 = []\n",
    "for table in table_list[:8]:\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[2:]\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.a['href']\n",
    "            links_2015_2022.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# deal with mislinked la tech 2019\n",
    "links_2015_2022[links_2015_2022.index('hthttps://texassports.com/boxscore.aspx?path=football&id=12601')] = 'https://texassports.com/boxscore.aspx?path=football&id=12601'\n",
    "\n",
    "# texas vs arkansas 2014\n",
    "links_2015_2022.append('http://texassports.com/boxscore.aspx?path=football&id=8599')\n",
    "\n",
    "for i in tqdm(range(len(links_2015_2022)), desc = \"Database building...\"):\n",
    "# for i in range(len(links_2015_2022)):\n",
    "    url = links_2015_2022[i]\n",
    "    # driver.get(url)\n",
    "    # driver.implicitly_wait(2) # wait a bit\n",
    "    # page_source = driver.page_source\n",
    "    # soup = BeautifulSoup(page_source)\n",
    "\n",
    "    response = make_request(url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        # print(url)\n",
    "        driver.get(url)\n",
    "        # driver.implicitly_wait(2) # wait a bit\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "\n",
    "    individual_stats = soup.find('section', id='individual-stats')\n",
    "    tables = individual_stats.find_all('table')\n",
    "\n",
    "    score_table = soup.find('table')\n",
    "    score_table = score_table.find_all('td')\n",
    "    for i in range(1, len(score_table)):\n",
    "        try:\n",
    "            x = int(score_table[i+1].text)\n",
    "        except:\n",
    "            ascore = float(score_table[i].text)\n",
    "            home_team = score_table[i+1].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "            break\n",
    "\n",
    "    away_team = score_table[0].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "    hscore = float(score_table[-1].text)\n",
    "\n",
    "    home_team = home_team.replace(\"Winner\", \"\")\n",
    "    away_team = away_team.replace(\"Winner\", \"\")\n",
    "\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get date\n",
    "    big_html = soup.text\n",
    "    date_index = big_html.find('Date:')\n",
    "    date_endex = big_html.find('Site:')\n",
    "    date = big_html[date_index + 6: date_endex].strip()\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "\n",
    "    # make gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "\n",
    "    if home_team == 'texas':\n",
    "        tex_pass = tables[1]\n",
    "        tex_rush = tables[3]\n",
    "        tex_rec = tables[5]\n",
    "    else:\n",
    "        tex_pass = tables[0]\n",
    "        tex_rush = tables[2]\n",
    "        tex_rec = tables[4]\n",
    "\n",
    "    tex_pass_stats = tex_pass.find_all('td')\n",
    "    for i in range(len(tex_pass_stats)):  # convert passers to text\n",
    "        tex_pass_stats[i] = tex_pass_stats[i].text.strip()\n",
    "    passer_temp = []\n",
    "    tex_pass_stats_final = []\n",
    "    for i in range(len(tex_pass_stats)):\n",
    "        passer_temp.append(tex_pass_stats[i])\n",
    "        if len(passer_temp)/8 == 1:\n",
    "            tex_pass_stats_final.append(passer_temp)\n",
    "            passer_temp = []\n",
    "    for i in range(len(tex_pass_stats_final)):\n",
    "        for j in range(1, len(tex_pass_stats_final[i])):\n",
    "            tex_pass_stats_final[i][j] = float(tex_pass_stats_final[i][j])\n",
    "    tex_pass_stats_final = pd.DataFrame(tex_pass_stats_final)\n",
    "    tex_pass_stats_final.columns = ['Player', 'Completions', 'Pass Attempts', 'Pass Yards', 'Passing TDs', 'Interceptions', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    tex_rush_stats = tex_rush.find_all('td')\n",
    "    for i in range(len(tex_rush_stats)):  # convert passers to text\n",
    "        tex_rush_stats[i] = tex_rush_stats[i].text.strip()\n",
    "    rusher_temp = []\n",
    "    tex_rush_stats_final = []\n",
    "    for i in range(len(tex_rush_stats)):\n",
    "        rusher_temp.append(tex_rush_stats[i])\n",
    "        if len(rusher_temp)/8 == 1:\n",
    "            tex_rush_stats_final.append(rusher_temp)\n",
    "            rusher_temp = []\n",
    "    for i in range(len(tex_rush_stats_final)):\n",
    "        for j in range(1, len(tex_rush_stats_final[i])):\n",
    "            tex_rush_stats_final[i][j] = float(tex_rush_stats_final[i][j])\n",
    "    tex_rush_stats_final = pd.DataFrame(tex_rush_stats_final)\n",
    "    tex_rush_stats_final.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    tex_rec_stats = tex_rec.find_all('td')\n",
    "    for i in range(len(tex_rec_stats)):  # convert passers to text\n",
    "        tex_rec_stats[i] = tex_rec_stats[i].text.strip()\n",
    "    recer_temp = []\n",
    "    tex_rec_stats_final = []\n",
    "    for i in range(len(tex_rec_stats)):\n",
    "        recer_temp.append(tex_rec_stats[i])\n",
    "        if len(recer_temp)/5 == 1:\n",
    "            tex_rec_stats_final.append(recer_temp)\n",
    "            recer_temp = []\n",
    "    for i in range(len(tex_rec_stats_final)):\n",
    "        for j in range(1, len(tex_rec_stats_final[i])):\n",
    "            tex_rec_stats_final[i][j] = float(tex_rec_stats_final[i][j])\n",
    "    tex_rec_stats_final = pd.DataFrame(tex_rec_stats_final)\n",
    "    tex_rec_stats_final.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        tex_pass_stats_final, tex_rush_stats_final, how = \"outer\", on = \"Player\")\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        full_game_stats, tex_rec_stats_final, how = 'outer', on = \"Player\")\n",
    "\n",
    "    full_game_stats = full_game_stats.fillna(0)\n",
    "\n",
    "    full_game_stats['GameID'] = gameid\n",
    "    full_game_stats['Date'] = date\n",
    "    full_game_stats['Home Team'] = home_team\n",
    "    full_game_stats['Away Team'] = away_team\n",
    "    full_game_stats['Home Score'] = hscore\n",
    "    full_game_stats['Away Score'] = ascore\n",
    "    full_game_stats['Texas Result'] = tex_win\n",
    "    full_game_stats['Link'] = url\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_3 = pd.concat([master_stats_3, full_game_stats], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_3.to_csv(\"master_stats_3.csv\", index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get glitched blue box scores kansas and nebraska 2009 (probably wouldn't have bothered with these if I knew it was just two games but its nice not to do manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_4 = pd.DataFrame(stats)\n",
    "\n",
    "link_list = ['https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/big12fb.html', # nebraska 2009\n",
    "             'https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html'] # kansas 2009\n",
    "\n",
    "for i in tqdm(range(len(link_list)), desc = \"Database building...\"):\n",
    "    link = link_list[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex - 3].strip()\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    tables = temp_box_soup.find_all(\"table\")\n",
    "    score_table = tables[3]\n",
    "    away_t_row = 1\n",
    "    home_t_row = 2\n",
    "\n",
    "    away_t_col = 0\n",
    "    home_t_col = 0\n",
    "\n",
    "    away_s_col = 5\n",
    "    home_s_col = 5\n",
    "\n",
    "    home_team = score_table.find_all('tr')[home_t_row].find_all('td')[home_t_col].text.strip().lower()\n",
    "    away_team = score_table.find_all('tr')[away_t_row].find_all('td')[away_t_col].text.strip().lower()\n",
    "    ascore = float(score_table.find_all('tr')[away_t_row].find_all('td')[away_s_col].text.strip())\n",
    "    hscore = float(score_table.find_all('tr')[home_t_row].find_all('td')[home_s_col].text.strip())\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"     \n",
    "\n",
    "    if home_team == 'texas':\n",
    "        rush_table = tables[11]\n",
    "        pass_table = tables[13]\n",
    "        rec_table = tables[15]\n",
    "    else:\n",
    "        rush_table = tables[10]\n",
    "        pass_table = tables[12]\n",
    "        rec_table = tables[14]\n",
    "\n",
    "    # rush stats\n",
    "    rush_2d = []\n",
    "    temp = []\n",
    "    for row in rush_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rush_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rush_col = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    rush_data = pd.DataFrame(rush_2d)\n",
    "    rush_data.columns = rush_col\n",
    "\n",
    "    # pass stats\n",
    "    pass_2d = []\n",
    "    temp = []\n",
    "    for row in pass_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            pass_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    for row in pass_2d:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "\n",
    "    pass_col = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_2d)\n",
    "    pass_data.columns = pass_col\n",
    "\n",
    "    # pass stats\n",
    "    rec_2d = []\n",
    "    temp = []\n",
    "    for row in rec_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rec_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rec_col = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "            \n",
    "    frames = [pass_2d, rush_2d, rec_2d]\n",
    "    for frame in frames:\n",
    "        for i in range(0,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_2d)\n",
    "    rec_data.columns = rec_col\n",
    "\n",
    "    full_game_data = pd.merge(pass_data, rush_data, how = \"outer\", on = \"Player\")\n",
    "    full_game_data = pd.merge(full_game_data, rec_data, how = 'outer', on = \"Player\")\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "\n",
    "    numeric_cols = full_game_data.select_dtypes(include='number').columns\n",
    "    full_game_data[numeric_cols] = full_game_data[numeric_cols].astype(float)\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_4 = pd.concat([master_stats_4, full_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_4.to_csv(\"master_stats_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2008 (i do not like 2008\n",
    "        i do not like it in a gate\n",
    "            i do not like it when it skate\n",
    "                i do not like 2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://stats.texassports.com/sports/m-footbl/2008-2009/ut1.html\n",
      "Passing\tAtt-Cmp-Int\tYds\tTD\tLong\tSack\t\n",
      "Smith, Rusty\t31-15-1\t253\t1\t62\t0\t\n",
      "VanCamp, Jeff\t8-2-0\t2\t0\t5\t0\t\n",
      "Totals...\t39-17-1\t255\t1\t62\t0\t\n",
      "Rushing\tNo\tGain\tLoss\tNet\tTD\tLg\tAvg\t\n",
      "Edgecomb, D.\t4\t19\t0\t19\t0\t11\t4.8\t\n",
      "Floyd, Willie\t4\t16\t1\t15\t0\t15\t3.8\t\n",
      "Rose, Willie\t3\t16\t1\t15\t0\t13\t5.0\t\n",
      "VanCamp, Jeff\t1\t6\t0\t6\t0\t6\t6.0\t\n",
      "Pierre, Charles\t6\t10\t7\t3\t0\t6\t0.5\t\n",
      "Blanchard, Jeff\t2\t3\t1\t2\t0\t3\t1.0\t\n",
      "Morris, Alfred\t1\t0\t0\t0\t0\t0\t0.0\t\n",
      "Smith, Rusty\t1\t0\t0\t0\t0\t0\t0.0\t\n",
      "TEAM\t1\t0\t23\t-23\t0\t0\t-23.0\t\n",
      "Totals...\t23\t70\t33\t37\t0\t15\t1.6\t\n",
      "\n",
      "Receiving\tNo.\tYds\tTD\tLong\t\n",
      "Grant, Jamari\t4\t93\t0\t62\t\n",
      "Gent, Cortez\t3\t59\t0\t33\t\n",
      "Housler, Rob\t2\t53\t1\t33\t\n",
      "Bonner, Chris\t2\t27\t0\t15\t\n",
      "Rose, Willie\t2\t24\t0\t22\t\n",
      "Fick, Carl\t1\t5\t0\t5\t\n",
      "Jean, Lester\t1\t0\t0\t0\t\n",
      "Johnson, C.\t1\t-3\t0\t0\t\n",
      "Edgecomb, D.\t1\t-3\t0\t0\t\n",
      "Totals...\t17\t255\t1\t62\t\n",
      "\n",
      "http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html\n",
      "Passing\tAtt-Cmp-Int\tYds\tTD\tLong\tSack\t\n",
      "McCoy, Colt\t29-20-1\t282\t4\t39\t1\t\n",
      "Totals...\t29-20-1\t282\t4\t39\t1\t\n",
      "\n",
      "\n",
      "Receiving\tNo.\tYds\tTD\tLong\t\n",
      "Cosby, Quan\t8\t154\t1\t39\t\n",
      "Ogbonnaya, Chris\t3\t35\t0\t14\t\n",
      "Shipley, Jordan\t3\t30\t1\t15\t\n",
      "Collins, Brandon\t2\t22\t0\t16\t\n",
      "Williams, Malcolm\t2\t6\t0\t7\t\n",
      "Irby, Blaine\t1\t23\t1\t23\t\n",
      "Buckner, Dan\t1\t12\t1\t12\t\n",
      "Totals...\t20\t282\t4\t39\t\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 8 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Code\\ut_football_history\\texas_football_scrape.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Code/ut_football_history/texas_football_scrape.ipynb#X26sZmlsZQ%3D%3D?line=270'>271</a>\u001b[0m \u001b[39m# Now, we make the arrays into dataframes using panda\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Code/ut_football_history/texas_football_scrape.ipynb#X26sZmlsZQ%3D%3D?line=271'>272</a>\u001b[0m \u001b[39m# admittedly i shouldve done this earlier but oh well\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Code/ut_football_history/texas_football_scrape.ipynb#X26sZmlsZQ%3D%3D?line=272'>273</a>\u001b[0m rush_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(rush_stats[\u001b[39m1\u001b[39m:])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Code/ut_football_history/texas_football_scrape.ipynb#X26sZmlsZQ%3D%3D?line=273'>274</a>\u001b[0m rush_data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mPlayer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRush Attempts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRush Yards Gained\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRush Yards Lost\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNet Rush Yards\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRushing TDs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLongest Rush\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mYards Per Rush\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Code/ut_football_history/texas_football_scrape.ipynb#X26sZmlsZQ%3D%3D?line=275'>276</a>\u001b[0m pass_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(pass_stats[\u001b[39m1\u001b[39m:])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Code/ut_football_history/texas_football_scrape.ipynb#X26sZmlsZQ%3D%3D?line=276'>277</a>\u001b[0m pass_data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mPlayer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPass Attempts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCompletions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mInterceptions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPass Yards\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPassing TDs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLongest Pass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSacks Taken\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\slq29\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5915\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5913\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   5914\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m-> 5915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, name, value)\n\u001b[0;32m   5916\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m   5917\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\slq29\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\slq29\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:823\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, labels: AnyArrayLike \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    822\u001b[0m     labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 823\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mset_axis(axis, labels)\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\slq29\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:230\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\slq29\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 8 elements"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_5 = pd.DataFrame(stats)\n",
    "\n",
    "link_list = ['http://stats.texassports.com/sports/m-footbl/2008-2009/ut1.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut3.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut4.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut5.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut6.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut7.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut8.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut9.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut10.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut11.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut12.html',            \n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut13.html']\n",
    "\n",
    "# for i in tqdm(range(len(link_list)), desc = \"Database building...\"):\n",
    "for i in range(len(link_list)):\n",
    "    # Get full page soup\n",
    "    link = link_list[i]\n",
    "    print(link)\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/06/ut11.htm') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex].strip()\n",
    "    if date == \"0ct 10, 1959\":\n",
    "        date = \"Oct 10, 1959\"\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    # Get away team\n",
    "    away_index = temp_text.find('Photo Gallery')\n",
    "    away_endex = temp_text.find(' vs ')\n",
    "    away_team = temp_text[away_index + 13: away_endex].strip().lower()\n",
    "\n",
    "    # Get home team\n",
    "    home_index = temp_text.find(' vs ')\n",
    "    home_endex = temp_text.find(' (')\n",
    "    home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "    # get away score\n",
    "    temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "    temp_text_new = temp_text[temp_index:]\n",
    "    temp_index = temp_text_new.find('\\n')\n",
    "    temp_text_new = temp_text_new[temp_index + 1:]\n",
    "    temp_index = temp_text_new.find('\\n')\n",
    "    temp_text_new = temp_text_new[temp_index + 1:]\n",
    "    ascore_index = temp_text_new.find(' - ') + 3\n",
    "    ascore_endex = temp_text_new.find('\\n')\n",
    "    ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "    ascore = float(ascore)\n",
    "\n",
    "    # get home score\n",
    "    temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "    hscore_index = temp_text_new.find(' - ') + 3\n",
    "    hscore_endex = temp_text_new.find('\\n')\n",
    "    hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "    hscore = float(hscore)\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get UT box score text\n",
    "    temp = temp_box_soup.text\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    temp = temp.replace('Texas Longhorns', 'Texas')\n",
    "    temp = temp.replace('TEXAS', 'Texas')\n",
    "\n",
    "    start = temp.find('Texas')\n",
    "    temp = temp[start + 5:]\n",
    "    start = temp.find('Texas')\n",
    "    temp = temp[start + 5:]\n",
    "    start = temp.find('Texas')\n",
    "    temp = temp[start + 5:]\n",
    "    end = temp.find('Punting               No.  Yds   Avg Long In20')\n",
    "    temp = temp[start:end]\n",
    "\n",
    "    # Truncate box score for rushing stats\n",
    "    rush_start = temp.find('Rushing              No Gain Loss  Net TD Lg  Avg')\n",
    "    rush_end = temp.find('Passing              ') - 2\n",
    "    rush_temp = temp[rush_start:rush_end]\n",
    "\n",
    "    # Get rushing stats\n",
    "    rush_stats = []    \n",
    "    line_break = rush_temp.find('\\n')\n",
    "    header = rush_temp[0:line_break].split()\n",
    "    rush_stats.append(header)\n",
    "    rush_temp = rush_temp[line_break:]\n",
    "    line_break = rush_temp.find('\\n')\n",
    "    rush_temp = rush_temp[line_break + 1:]\n",
    "\n",
    "    # Now rush temp has no header\n",
    "    line_break = rush_temp.find('\\n')\n",
    "    rush_temp = rush_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        line = rush_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if rush_temp.find('\\n') == -1:\n",
    "            line = rush_temp\n",
    "            game_stat = line.split()          \n",
    "            rush_stats.append(game_stat)\n",
    "            rush_temp = rush_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 8: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            rush_stats.append(game_stat)\n",
    "            rush_temp = rush_temp[line_break + 1:]\n",
    "    \n",
    "    # Truncate box score for passing stats\n",
    "    pass_start = temp.find('Passing              ')\n",
    "    pass_end = temp.find('Receiving             No.  Yds   TD Long') - 3\n",
    "    pass_temp = temp[pass_start:pass_end]\n",
    "\n",
    "    # Get passing stats\n",
    "    pass_stats = []    \n",
    "    line_break = pass_temp.find('\\n')\n",
    "    header = pass_temp[0:line_break].split()\n",
    "    pass_stats.append(header)\n",
    "    pass_temp = pass_temp[line_break:]\n",
    "    line_break = pass_temp.find('\\n')\n",
    "    pass_temp = pass_temp[line_break + 1:]\n",
    "\n",
    "    # Now pass temp has no header\n",
    "    line_break = pass_temp.find('\\n')\n",
    "    pass_temp = pass_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        line = pass_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if pass_temp.find('\\n') == -1:\n",
    "            line = pass_temp\n",
    "            game_stat = line.split()\n",
    "            pass_stats.append(game_stat)\n",
    "            pass_temp = pass_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 6: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            pass_stats.append(game_stat)\n",
    "            pass_temp = pass_temp[line_break + 1:]\n",
    "    \n",
    "    # Truncate box score for rec stats\n",
    "    rec_start = temp.find('Receiving             No.  Yds   TD Long')\n",
    "    rec_temp = temp[rec_start:-2]\n",
    "\n",
    "    # Get rec stats\n",
    "    rec_stats = []    \n",
    "    line_break = rec_temp.find('\\n')\n",
    "    header = rec_temp[0:line_break].split()\n",
    "    rec_stats.append(header)\n",
    "    rec_temp = rec_temp[line_break:]\n",
    "    line_break = rec_temp.find('\\n')\n",
    "    rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "    # Now rec temp has no header\n",
    "    line_break = rec_temp.find('\\n')\n",
    "    rec_temp = rec_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        line = rec_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if rec_temp.find('\\n') == -1:\n",
    "            line = rec_temp\n",
    "            game_stat = line.split()\n",
    "            rec_stats.append(game_stat)\n",
    "            rec_temp = rec_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 5: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            rec_stats.append(game_stat)\n",
    "            rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "    ##############################################################\n",
    "    # Now that we have the stats in 2d lists, we need to make sure they aren't just strings\n",
    "\n",
    "    print_table(pass_stats)\n",
    "    print_table(rush_stats)\n",
    "    print_table(rec_stats)\n",
    "\n",
    "    # First, we must address the formatting of the passing cmp-att-int format\n",
    "    for row in pass_stats:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "    \n",
    "    # Next, we must make sure the elements are floats and not strings\n",
    "    frames = [pass_stats, rush_stats, rec_stats]\n",
    "    for frame in frames:\n",
    "        for i in range(1,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "                \n",
    "    # Now, we make the arrays into dataframes using panda\n",
    "    # admittedly i shouldve done this earlier but oh well\n",
    "    rush_data = pd.DataFrame(rush_stats[1:])\n",
    "    rush_data.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_stats[1:])\n",
    "    pass_data.columns = ['Player', 'Pass Attempts', 'Completions', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_stats[1:])\n",
    "    rec_data.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "    \n",
    "    # Finally, time to merge the data into one full dataframe for the full game\n",
    "    full_game_data = pd.merge(\n",
    "        pass_data, rush_data, how = \"outer\", on = \"Player\"\n",
    "    )\n",
    "    full_game_data = pd.merge(\n",
    "        full_game_data, rec_data, how = 'outer', on = \"Player\"\n",
    "    )\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    # small thing but i want to take the ellipsis out of the totals category\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    # now make the gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    '''\n",
    "    game_df = {'Home Team' : [home_team],\n",
    "            'Away Team' : [away_team],\n",
    "            'Home Score' : [hscore],\n",
    "            'Away Score' : [ascore],\n",
    "            'Texas Result' : [tex_win],\n",
    "            'Box Score' : [full_game_data]\n",
    "            }\n",
    "    \n",
    "    game_df = pd.DataFrame(game_df, index = gameid_list)\n",
    "\n",
    "    # finally append it to the master games\n",
    "    master_games = pd.concat([master_games, game_df], ignore_index = True)\n",
    "\n",
    "    # empty out game_df\n",
    "    game_df = pd.DataFrame()\n",
    "    '''\n",
    "\n",
    "    ##############################################################\n",
    "    # the last thing I want to do is to create one large dataframe with every single game performance ever\n",
    "    # this will contain duplicate players for their different performances in different games\n",
    "    # much less concise, much more usefull (probably)\n",
    "    # first add gameid column\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_5 = pd.concat([master_stats_5, full_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "        \n",
    "# print(master_stats_1)\n",
    "master_stats_5.to_csv('master_stats_5.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things i need to fix:\n",
    "- north texas glitch [done]\n",
    "- la tech 2019 (maybe this will run now) [done]\n",
    "- 3 games in 1998 [done]\n",
    "- arkansas 2014 [done]\n",
    "- add link to blue tables and new format [done]\n",
    "- 2008, kansas 2009, nebraska 2009 [2008: X, K2009: Y, N2009: Y]\n",
    "- performance_id instead of game_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name   Last Name  Completions  Pass Attempts  Interceptions  \\\n",
      "0        Colt       McCoy         32.0           41.0            0.0   \n",
      "1     Garrett     Gilbert          0.0            1.0            0.0   \n",
      "2         0.0       Total         32.0           42.0            0.0   \n",
      "3        Tre'      Newton          0.0            0.0            0.0   \n",
      "4    Vondrell       McGee          0.0            0.0            0.0   \n",
      "5        Cody     Johnson          0.0            0.0            0.0   \n",
      "6    Foswhitt   Whittaker          0.0            0.0            0.0   \n",
      "7    Marquise     Goodwin          0.0            0.0            0.0   \n",
      "8      Jordan     Shipley          0.0            0.0            0.0   \n",
      "9       James  Kirkendoll          0.0            0.0            0.0   \n",
      "10    Malcolm    Williams          0.0            0.0            0.0   \n",
      "11       Tre'      Newton          0.0            0.0            0.0   \n",
      "12   Marquise     Goodwin          0.0            0.0            0.0   \n",
      "13       John      Chiles          0.0            0.0            0.0   \n",
      "14        Dan     Buckner          0.0            0.0            0.0   \n",
      "\n",
      "    Pass Yards  Passing TDs  Longest Pass  Sacks Taken  Rush Attempts  ...  \\\n",
      "0        396.0          4.0          68.0          3.0           12.0  ...   \n",
      "1          0.0          0.0           0.0          0.0            0.0  ...   \n",
      "2        396.0          4.0          68.0          3.0           40.0  ...   \n",
      "3          0.0          0.0           0.0          0.0           12.0  ...   \n",
      "4          0.0          0.0           0.0          0.0            3.0  ...   \n",
      "5          0.0          0.0           0.0          0.0            8.0  ...   \n",
      "6          0.0          0.0           0.0          0.0            4.0  ...   \n",
      "7          0.0          0.0           0.0          0.0            1.0  ...   \n",
      "8          0.0          0.0           0.0          0.0            0.0  ...   \n",
      "9          0.0          0.0           0.0          0.0            0.0  ...   \n",
      "10         0.0          0.0           0.0          0.0            0.0  ...   \n",
      "11         0.0          0.0           0.0          0.0            0.0  ...   \n",
      "12         0.0          0.0           0.0          0.0            0.0  ...   \n",
      "13         0.0          0.0           0.0          0.0            0.0  ...   \n",
      "14         0.0          0.0           0.0          0.0            0.0  ...   \n",
      "\n",
      "    Receiving TDs  Longest Reception                   GameID  \\\n",
      "0             0.0                0.0  kansas_texas_11_21_2009   \n",
      "1             0.0                0.0  kansas_texas_11_21_2010   \n",
      "2             4.0               68.0  kansas_texas_11_21_2011   \n",
      "3             0.0                0.0  kansas_texas_11_21_2012   \n",
      "4             0.0                0.0  kansas_texas_11_21_2013   \n",
      "5             0.0                0.0  kansas_texas_11_21_2014   \n",
      "6             0.0                0.0  kansas_texas_11_21_2015   \n",
      "7             0.0                0.0  kansas_texas_11_21_2016   \n",
      "8             1.0               38.0  kansas_texas_11_21_2017   \n",
      "9             2.0               41.0  kansas_texas_11_21_2018   \n",
      "10            1.0               68.0  kansas_texas_11_21_2019   \n",
      "11            0.0               17.0  kansas_texas_11_21_2020   \n",
      "12            0.0               34.0  kansas_texas_11_21_2021   \n",
      "13            0.0               14.0  kansas_texas_11_21_2022   \n",
      "14            0.0               13.0  kansas_texas_11_21_2023   \n",
      "\n",
      "                                                 Link        Date  Home Team  \\\n",
      "0   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "1   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "2   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "3   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "4   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "5   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "6   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "7   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "8   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "9   https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "10  https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "11  https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "12  https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "13  https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "14  https://stats.texassports.com/custompages/spor...  11/21/2009      texas   \n",
      "\n",
      "    Away Team  Home Score  Away Score  Texas Result  \n",
      "0      kansas        51.0        20.0           Win  \n",
      "1      kansas        51.0        20.0           Win  \n",
      "2      kansas        51.0        20.0           Win  \n",
      "3      kansas        51.0        20.0           Win  \n",
      "4      kansas        51.0        20.0           Win  \n",
      "5      kansas        51.0        20.0           Win  \n",
      "6      kansas        51.0        20.0           Win  \n",
      "7      kansas        51.0        20.0           Win  \n",
      "8      kansas        51.0        20.0           Win  \n",
      "9      kansas        51.0        20.0           Win  \n",
      "10     kansas        51.0        20.0           Win  \n",
      "11     kansas        51.0        20.0           Win  \n",
      "12     kansas        51.0        20.0           Win  \n",
      "13     kansas        51.0        20.0           Win  \n",
      "14     kansas        51.0        20.0           Win  \n",
      "\n",
      "[15 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# fill n/as and float the numbers\n",
    "manual_input_stats = pd.read_csv(\"texas manual input stats - Sheet1.csv\")\n",
    "manual_input_stats = manual_input_stats.fillna(float(0))\n",
    "numeric_cols = manual_input_stats.select_dtypes(include='number').columns\n",
    "manual_input_stats[numeric_cols] = manual_input_stats[numeric_cols].astype(float)\n",
    "\n",
    "print(manual_input_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the master stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "master_stats_1 = pd.read_csv('master_stats_1.csv')\n",
    "master_stats_2 = pd.read_csv('master_stats_2.csv')\n",
    "master_stats_3 = pd.read_csv('master_stats_3.csv')\n",
    "\n",
    "master_stats = pd.concat([master_stats_1, master_stats_2, master_stats_3], ignore_index=True)\n",
    "master_stats.to_csv('master_stats.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up\n",
    "- give first and last name columns\n",
    "- strip the names\n",
    "- put names in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_names(row):\n",
    "    full_name = row['Last Name']\n",
    "    if pd.notna(full_name) and pd.isna(row['First Name']):\n",
    "        names = full_name.split()\n",
    "        if len(names) == 2:\n",
    "            row['First Name'] = names[0]\n",
    "            row['Last Name'] = names[1]\n",
    "    return row\n",
    "\n",
    "master_stats_test = pd.read_csv('master_stats.csv')\n",
    "\n",
    "# who the fuck did this to johnny walker 4 times i do not understand\n",
    "master_stats_test['Player'].replace('Walker. Johnny', 'Walker, Johnny', inplace = True)\n",
    "\n",
    "# split on commas\n",
    "master_stats_test[['Last Name', 'First Name']] = master_stats_test['Player'].str.split(pat=',', n=1, expand=True)\n",
    "master_stats_test = master_stats_test.drop('Player', axis=1)\n",
    "\n",
    "# strip the names\n",
    "master_stats_test['Last Name'] = master_stats_test['Last Name'].str.strip()\n",
    "master_stats_test['First Name'] = master_stats_test['First Name'].str.strip()\n",
    "\n",
    "# fix players with \"First Last\" Format\n",
    "master_stats_test = master_stats_test.apply(split_names, axis=1) \n",
    "\n",
    "# order the cols\n",
    "front_columns = ['First Name', 'Last Name']\n",
    "master_stats_test = master_stats_test[front_columns + [col for col in master_stats_test.columns if col not in front_columns]]\n",
    "\n",
    "# change totals to total\n",
    "master_stats_test['Last Name'].replace(\"Total\", \"Game\", inplace = True)\n",
    "master_stats_test['Last Name'].replace(\"Totals\", \"Game\", inplace = True)\n",
    "\n",
    "master_stats_test.to_csv('master_stats_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
