{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(matrix):\n",
    "    for row in matrix:\n",
    "        for element in row:\n",
    "            print(element, end='\\t')  # Separate elements by a tab (or any delimiter you prefer)\n",
    "        print()  # Move to the next line for the next row\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def modern_style_scrape(link):\n",
    "    response = make_request(link)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        # print(link)\n",
    "        driver.get(link)\n",
    "        # driver.implicitly_wait(2) # wait a bit\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "        driver.quit()\n",
    "\n",
    "    individual_stats = soup.find('section', id='individual-stats')\n",
    "    tables = individual_stats.find_all('table')\n",
    "\n",
    "    score_table = soup.find('table')\n",
    "    score_table = score_table.find_all('td')\n",
    "    for i in range(1, len(score_table)):\n",
    "        try:\n",
    "            x = int(score_table[i+1].text)\n",
    "        except:\n",
    "            ascore = float(score_table[i].text)\n",
    "            home_team = score_table[i+1].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "            break\n",
    "\n",
    "    away_team = score_table[0].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "    hscore = float(score_table[-1].text)\n",
    "\n",
    "    home_team = home_team.replace(\"Winner\", \"\")\n",
    "    away_team = away_team.replace(\"Winner\", \"\")\n",
    "\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get date\n",
    "    big_html = soup.text\n",
    "    date_index = big_html.find('Date:')\n",
    "    date_endex = big_html.find('Site:')\n",
    "    date = big_html[date_index + 6: date_endex].strip()\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "\n",
    "    # make gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "\n",
    "    if home_team == 'texas':\n",
    "        tex_pass = tables[1]\n",
    "        tex_rush = tables[3]\n",
    "        tex_rec = tables[5]\n",
    "    else:\n",
    "        tex_pass = tables[0]\n",
    "        tex_rush = tables[2]\n",
    "        tex_rec = tables[4]\n",
    "\n",
    "    tex_pass_stats = tex_pass.find_all('td')\n",
    "    for i in range(len(tex_pass_stats)):  # convert passers to text\n",
    "        tex_pass_stats[i] = tex_pass_stats[i].text.strip()\n",
    "    passer_temp = []\n",
    "    tex_pass_stats_final = []\n",
    "    for i in range(len(tex_pass_stats)):\n",
    "        passer_temp.append(tex_pass_stats[i])\n",
    "        if len(passer_temp)/8 == 1:\n",
    "            tex_pass_stats_final.append(passer_temp)\n",
    "            passer_temp = []\n",
    "    for i in range(len(tex_pass_stats_final)):\n",
    "        for j in range(1, len(tex_pass_stats_final[i])):\n",
    "            tex_pass_stats_final[i][j] = float(tex_pass_stats_final[i][j])\n",
    "    tex_pass_stats_final = pd.DataFrame(tex_pass_stats_final)\n",
    "    tex_pass_stats_final.columns = ['Player', 'Completions', 'Pass Attempts', 'Pass Yards', 'Passing TDs', 'Interceptions', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    tex_rush_stats = tex_rush.find_all('td')\n",
    "    for i in range(len(tex_rush_stats)):  # convert passers to text\n",
    "        tex_rush_stats[i] = tex_rush_stats[i].text.strip()\n",
    "    rusher_temp = []\n",
    "    tex_rush_stats_final = []\n",
    "    for i in range(len(tex_rush_stats)):\n",
    "        rusher_temp.append(tex_rush_stats[i])\n",
    "        if len(rusher_temp)/8 == 1:\n",
    "            tex_rush_stats_final.append(rusher_temp)\n",
    "            rusher_temp = []\n",
    "    for i in range(len(tex_rush_stats_final)):\n",
    "        for j in range(1, len(tex_rush_stats_final[i])):\n",
    "            tex_rush_stats_final[i][j] = float(tex_rush_stats_final[i][j])\n",
    "    tex_rush_stats_final = pd.DataFrame(tex_rush_stats_final)\n",
    "    tex_rush_stats_final.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    tex_rec_stats = tex_rec.find_all('td')\n",
    "    for i in range(len(tex_rec_stats)):  # convert passers to text\n",
    "        tex_rec_stats[i] = tex_rec_stats[i].text.strip()\n",
    "    recer_temp = []\n",
    "    tex_rec_stats_final = []\n",
    "    for i in range(len(tex_rec_stats)):\n",
    "        recer_temp.append(tex_rec_stats[i])\n",
    "        if len(recer_temp)/5 == 1:\n",
    "            tex_rec_stats_final.append(recer_temp)\n",
    "            recer_temp = []\n",
    "    for i in range(len(tex_rec_stats_final)):\n",
    "        for j in range(1, len(tex_rec_stats_final[i])):\n",
    "            tex_rec_stats_final[i][j] = float(tex_rec_stats_final[i][j])\n",
    "    tex_rec_stats_final = pd.DataFrame(tex_rec_stats_final)\n",
    "    tex_rec_stats_final.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        tex_pass_stats_final, tex_rush_stats_final, how = \"outer\", on = \"Player\")\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        full_game_stats, tex_rec_stats_final, how = 'outer', on = \"Player\")\n",
    "\n",
    "    full_game_stats = full_game_stats.fillna(0)\n",
    "\n",
    "    full_game_stats['GameID'] = gameid\n",
    "    full_game_stats['Date'] = date\n",
    "    full_game_stats['Home Team'] = home_team\n",
    "    full_game_stats['Away Team'] = away_team\n",
    "    full_game_stats['Home Score'] = hscore\n",
    "    full_game_stats['Away Score'] = ascore\n",
    "    full_game_stats['Texas Result'] = tex_win\n",
    "    full_game_stats['Link'] = link\n",
    "\n",
    "    return full_game_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years 1947 - 2007 (excluding the three games in 98) -> stored in master_stats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 60/60 [05:25<00:00,  5.42s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_1 = pd.DataFrame(stats)\n",
    "\n",
    "games = {\n",
    "    'Home Team' : [],\n",
    "    'Away Team'\t: [],\n",
    "    'Home Score' : [],\n",
    "    'Away Score' : [],\n",
    "    'Texas Result' : [],\n",
    "    'Box Score' : []\n",
    "}\n",
    "master_games_1 = pd.DataFrame(games)\n",
    "\n",
    "missed_games_1 = []\n",
    "\n",
    "# get links for each season\n",
    "years_list = [str(47), str(48)]\n",
    "for i in range(50, 100):\n",
    "    years_list.append(str(i))\n",
    "for i in range(0, 8):\n",
    "    years_list.append(f\"{i:02d}\")\n",
    "# years_list.append('08')\n",
    "\n",
    "season_links = []\n",
    "for i in years_list:\n",
    "    season_link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + i + '/teamstat.htm'\n",
    "    season_links.append(season_link)\n",
    "\n",
    "for x in tqdm(range(len(season_links)), desc = \"Database building...\"):\n",
    "    season = season_links[x] # paste specific season link here when troubleshooting\n",
    "    year = years_list[x] # change year manually to when troubleshooting\n",
    "    box_score_links = []\n",
    "    if year == '98':\n",
    "        box_score_links = ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ucla.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-msu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ksu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ou.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-bu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-nu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-osu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ttu.htm',\n",
    "                            'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-tam.htm']\n",
    "    # elif year == '08':\n",
    "    #     # 2008 links\n",
    "    #     box_score_links = ['http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut3.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut4.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut5.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut6.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut7.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut8.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut9.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut10.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut11.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut12.html', \n",
    "    #                         'http://stats.texassports.com/sports/m-footbl/2008-2009/ut13.html']\n",
    "    else:\n",
    "        # open season page\n",
    "        driver.get(season)\n",
    "        texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "        table = texas_sports_soup.find(\"table\")\n",
    "        rows = table.tbody.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            box_score = row.find_all('td')[-1]\n",
    "            try:\n",
    "                link_tail_temp = box_score.font.a['href']\n",
    "                if link_tail_temp == '../../index1919.html':\n",
    "                    missed_games_1.append(row.find_all('td')[-2].get_text())\n",
    "                else:\n",
    "                    built_link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + year + '/' + link_tail_temp\n",
    "                    box_score_links.append(built_link)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # must catch the random 90s TAMU games that are mislinked\n",
    "            if year in [str(91), str(92), str(93), str(95), str(96)]:\n",
    "                box_score_links.append('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/' + year + '/' + 'UT-A&M.HTM')\n",
    "\n",
    "    for link in box_score_links:\n",
    "        # print(link_tail, year)        \n",
    "        # Get full page soup\n",
    "        # link = 'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/92/ut_nt.htm' # troubleshooting\n",
    "        response = make_request(link)\n",
    "        temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "        if response == '':\n",
    "            driver.get(link)\n",
    "            # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/06/ut11.htm') # for troubleshooting\n",
    "            temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "        temp_text = temp_box_soup.text\n",
    "        temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "        temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "        if year == '06':\n",
    "            # Get away team\n",
    "            away_index = 0\n",
    "            away_endex = temp_text.find(' vs ')\n",
    "            away_team = temp_text[away_index: away_endex].strip().lower()\n",
    "\n",
    "            # Get home team\n",
    "            home_index = temp_text.find(' vs ')\n",
    "            home_endex = temp_text.find(' (')\n",
    "            home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "            # Get game date\n",
    "            date_index = temp_text.find('(')\n",
    "            date_endex = temp_text.find(\")\")\n",
    "            date = temp_text[date_index + 1: date_endex].strip()\n",
    "            date = date.replace(\",\", \"\")\n",
    "            date = date[:-4] + ',' + date[-4:]\n",
    "            date = date.replace(\"Sept\", \"Sep\")\n",
    "            date = date.replace(\" \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "            except ValueError:\n",
    "                date = datetime.strptime(date, \"%b.%d,%Y\")\n",
    "            \n",
    "            # get away score\n",
    "            temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "            temp_text_new = temp_text[temp_index:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            ascore_index = temp_text_new.find(' - ') + 3\n",
    "            ascore_endex = temp_text_new.find('Record: ')\n",
    "            ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "            ascore = float(ascore)\n",
    "\n",
    "            # get home score\n",
    "            temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "            hscore_index = temp_text_new.find(' - ') + 3\n",
    "            hscore_endex = temp_text_new.find('Record: ')\n",
    "            hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "            hscore = float(hscore)\n",
    "            \n",
    "        else:\n",
    "            # Get game date\n",
    "            date_index = temp_text.find('Date: ')\n",
    "            date_endex = temp_text.find(\"Site: \")\n",
    "            date = temp_text[date_index + 6: date_endex].strip()\n",
    "            if date == \"0ct 10, 1959\":\n",
    "                date = \"Oct 10, 1959\"\n",
    "            date = date.replace(\",\", \"\")\n",
    "            date = date[:-4] + ',' + date[-4:]\n",
    "            date = date.replace(\"Sept\", \"Sep\")\n",
    "            date = date.replace(\" \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "            except ValueError:\n",
    "                date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "            # Get away team\n",
    "            away_index = 0\n",
    "            away_endex = temp_text.find(' vs ')\n",
    "            away_team = temp_text[away_index: away_endex].strip().lower()\n",
    "\n",
    "            # Get home team\n",
    "            home_index = temp_text.find(' vs ')\n",
    "            home_endex = temp_text.find(' (')\n",
    "            home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "            # get away score\n",
    "            temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "            temp_text_new = temp_text[temp_index:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            temp_index = temp_text_new.find('\\n')\n",
    "            temp_text_new = temp_text_new[temp_index + 1:]\n",
    "            ascore_index = temp_text_new.find(' - ') + 3\n",
    "            ascore_endex = temp_text_new.find('\\n')\n",
    "            ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "            ascore = float(ascore)\n",
    "\n",
    "            # get home score\n",
    "            temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "            hscore_index = temp_text_new.find(' - ') + 3\n",
    "            hscore_endex = temp_text_new.find('\\n')\n",
    "            hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "            hscore = float(hscore)\n",
    "\n",
    "        # did texas win?\n",
    "        if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "            tex_win = \"Win\"\n",
    "        elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "            tex_win = \"Loss\"\n",
    "        else:\n",
    "            tex_win = \"Tie\"\n",
    "\n",
    "        # get UT box score text\n",
    "        temp = temp_box_soup.find('font', string = \"Individual Statistics\")\n",
    "        temp = temp.find_next('font', string = \"Individual Statistics\")\n",
    "        temp = temp.find_next('pre').text\n",
    "        temp = temp.replace('Texas Longhorns', 'Texas')\n",
    "        temp = temp.replace('TEXAS', 'Texas')\n",
    "        start = temp.find('\\nTexas\\n')\n",
    "        temp = temp[start:]\n",
    "        end = temp.find('Punting               No.  Yds   Avg Long In20')\n",
    "        temp = temp[:end]\n",
    "\n",
    "        # Truncate box score for rushing stats\n",
    "        rush_start = temp.find('Rushing              No Gain Loss  Net TD Lg  Avg')\n",
    "        rush_end = temp.find('Passing              ') - 2\n",
    "        rush_temp = temp[rush_start:rush_end]\n",
    "\n",
    "        # Get rushing stats\n",
    "        rush_stats = []    \n",
    "        line_break = rush_temp.find('\\n')\n",
    "        header = rush_temp[0:line_break].split()\n",
    "        rush_stats.append(header)\n",
    "        rush_temp = rush_temp[line_break:]\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        rush_temp = rush_temp[line_break + 1:]\n",
    "\n",
    "        # Now rush temp has no header\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        rush_temp = rush_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = rush_temp.find('\\n')\n",
    "            line = rush_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if rush_temp.find('\\n') == -1:\n",
    "                line = rush_temp\n",
    "                game_stat = line.split()          \n",
    "                rush_stats.append(game_stat)\n",
    "                rush_temp = rush_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 8: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                rush_stats.append(game_stat)\n",
    "                rush_temp = rush_temp[line_break + 1:]\n",
    "        \n",
    "        # Truncate box score for passing stats\n",
    "        pass_start = temp.find('Passing              ')\n",
    "        pass_end = temp.find('Receiving             No.  Yds   TD Long') - 2\n",
    "        pass_temp = temp[pass_start:pass_end]\n",
    "\n",
    "        # Get passing stats\n",
    "        pass_stats = []    \n",
    "        line_break = pass_temp.find('\\n')\n",
    "        header = pass_temp[0:line_break].split()\n",
    "        pass_stats.append(header)\n",
    "        pass_temp = pass_temp[line_break:]\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        pass_temp = pass_temp[line_break + 1:]\n",
    "\n",
    "        # Now pass temp has no header\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        pass_temp = pass_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = pass_temp.find('\\n')\n",
    "            line = pass_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if pass_temp.find('\\n') == -1:\n",
    "                line = pass_temp\n",
    "                game_stat = line.split()\n",
    "                pass_stats.append(game_stat)\n",
    "                pass_temp = pass_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 6: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                pass_stats.append(game_stat)\n",
    "                pass_temp = pass_temp[line_break + 1:]\n",
    "        \n",
    "        # Truncate box score for rec stats\n",
    "        rec_start = temp.find('Receiving             No.  Yds   TD Long')\n",
    "        rec_temp = temp[rec_start:-2]\n",
    "\n",
    "        # Get rec stats\n",
    "        rec_stats = []    \n",
    "        line_break = rec_temp.find('\\n')\n",
    "        header = rec_temp[0:line_break].split()\n",
    "        rec_stats.append(header)\n",
    "        rec_temp = rec_temp[line_break:]\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "        # Now rec temp has no header\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        rec_temp = rec_temp[line_break + 1:]\n",
    "        while True:\n",
    "            line_break = rec_temp.find('\\n')\n",
    "            line = rec_temp[0:line_break + 1]\n",
    "            game_stat = line.split()\n",
    "            if rec_temp.find('\\n') == -1:\n",
    "                line = rec_temp\n",
    "                game_stat = line.split()\n",
    "                rec_stats.append(game_stat)\n",
    "                rec_temp = rec_temp[line_break + 1:]\n",
    "                break\n",
    "            else:\n",
    "                # combines first n name columns\n",
    "                while len(game_stat) > 5: \n",
    "                    name = game_stat[0] + ' ' + game_stat[1]\n",
    "                    stats = game_stat[2:]\n",
    "                    game_stat = [name] + stats\n",
    "                rec_stats.append(game_stat)\n",
    "                rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "        ##############################################################\n",
    "        # Now that we have the stats in 2d lists, we need to make sure they aren't just strings\n",
    "\n",
    "        # First, we must address the formatting of the passing cmp-att-int format\n",
    "        for row in pass_stats:\n",
    "            new_element = row.pop(1).split('-')\n",
    "            row[1:1] = new_element\n",
    "        \n",
    "        # Next, we must make sure the elements are floats and not strings\n",
    "        frames = [pass_stats, rush_stats, rec_stats]\n",
    "        for frame in frames:\n",
    "            for i in range(1,len(frame)):\n",
    "                for j in range(1,len(frame[i])):\n",
    "                    frame[i][j] = float(frame[i][j])\n",
    "                    \n",
    "        # Now, we make the arrays into dataframes using panda\n",
    "        # admittedly i shouldve done this earlier but oh well\n",
    "        rush_data = pd.DataFrame(rush_stats[1:])\n",
    "        rush_data.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "        pass_data = pd.DataFrame(pass_stats[1:])\n",
    "        if 40 < float(year) < 89:\n",
    "            pass_data.columns = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "        else:\n",
    "            pass_data.columns = ['Player', 'Pass Attempts', 'Completions', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "\n",
    "        rec_data = pd.DataFrame(rec_stats[1:])\n",
    "        rec_data.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "        \n",
    "        # Finally, time to merge the data into one full dataframe for the full game\n",
    "        full_game_data = pd.merge(\n",
    "            pass_data, rush_data, how = \"outer\", on = \"Player\"\n",
    "        )\n",
    "        full_game_data = pd.merge(\n",
    "            full_game_data, rec_data, how = 'outer', on = \"Player\"\n",
    "        )\n",
    "        full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "        # small thing but i want to take the ellipsis out of the totals category\n",
    "        full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "        # now make the gameid\n",
    "        gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "        gameid_list = [gameid]\n",
    "\n",
    "        '''\n",
    "        game_df = {'Home Team' : [home_team],\n",
    "                'Away Team' : [away_team],\n",
    "                'Home Score' : [hscore],\n",
    "                'Away Score' : [ascore],\n",
    "                'Texas Result' : [tex_win],\n",
    "                'Box Score' : [full_game_data]\n",
    "                }\n",
    "        \n",
    "        game_df = pd.DataFrame(game_df, index = gameid_list)\n",
    "\n",
    "        # finally append it to the master games\n",
    "        master_games = pd.concat([master_games, game_df], ignore_index = True)\n",
    "\n",
    "        # empty out game_df\n",
    "        game_df = pd.DataFrame()\n",
    "        '''\n",
    "\n",
    "        ##############################################################\n",
    "        # the last thing I want to do is to create one large dataframe with every single game performance ever\n",
    "        # this will contain duplicate players for their different performances in different games\n",
    "        # much less concise, much more usefull (probably)\n",
    "        # first add gameid column\n",
    "        full_game_data['GameID'] = gameid\n",
    "        full_game_data['Date'] = date\n",
    "        full_game_data['Home Team'] = home_team\n",
    "        full_game_data['Away Team'] = away_team\n",
    "        full_game_data['Home Score'] = hscore\n",
    "        full_game_data['Away Score'] = ascore\n",
    "        full_game_data['Texas Result'] = tex_win\n",
    "        full_game_data['Link'] = link\n",
    "        \n",
    "        # now add it to the master stats\n",
    "        master_stats_1 = pd.concat([master_stats_1, full_game_data], ignore_index = True)\n",
    "\n",
    "        # finally empty out the full game dataframe\n",
    "        full_game_data = pd.DataFrame() \n",
    "        \n",
    "# print(master_stats_1)\n",
    "master_stats_1.to_csv('master_stats_1.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get stats from blue table style (3 games in 98 and 2009 -2014) \n",
    "note: i have skipped 2008 for the moment, also missing vs arkansas 2014 and vs kansas 2009 vs nebraska 2009\n",
    "-> stored in master_stats_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 73/73 [01:58<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_2 = pd.DataFrame(stats)\n",
    "\n",
    "games = {\n",
    "    'Home Team' : [],\n",
    "    'Away Team'\t: [],\n",
    "    'Home Score' : [],\n",
    "    'Away Score' : [],\n",
    "    'Texas Result' : [],\n",
    "    'Box Score' : []\n",
    "}\n",
    "master_games_2 = pd.DataFrame(games)\n",
    "\n",
    "missed_games_2 = []\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "game_links = []\n",
    "# 1998 links\n",
    "rows = table_list[24].tbody.find_all('tr')[2:]\n",
    "for row in rows:\n",
    "    box_score = row.find_all('td')[-1]\n",
    "    try:\n",
    "        link_temp = box_score.a['href']\n",
    "        game_links.append(link_temp)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "game_links = ['https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-isu.htm',\n",
    "              'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-ru.htm',\n",
    "              'https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/98/ut-nmsu.htm']\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# links for 2009-2014\n",
    "for table in table_list[8:14]:\n",
    "    # get year\n",
    "    # temp = table.find('td').get_text()\n",
    "    # year_index = temp.find('\\n')\n",
    "    # year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[3:]\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.find_all('a')[1]['href']\n",
    "            game_links.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "game_links.remove('http://texassports.com/boxscore.aspx?path=football&id=8599')\n",
    "game_links.remove('http://stats.texassports.com/sports/m-footbl/2009-2010/ut11.html')\n",
    "game_links.remove('http://stats.texassports.com/sports/m-footbl/2009-2010/big12fb.html')\n",
    "\n",
    "for i in tqdm(range(len(game_links)), desc = \"Database building...\"):\n",
    "# for i in range(len(game_links)):\n",
    "    # Get full page soup\n",
    "    link = game_links[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex - 3].strip()\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    tables = temp_box_soup.find_all(\"table\")\n",
    "    score_table = tables[2]\n",
    "    away_t_row = 1\n",
    "    home_t_row = 2\n",
    "    \n",
    "    away_t_col = 0\n",
    "    home_t_col = 0\n",
    "\n",
    "    away_s_col = 5\n",
    "    home_s_col = 5\n",
    "\n",
    "    home_team = score_table.find_all('tr')[home_t_row].find_all('td')[home_t_col].text.strip().lower()\n",
    "    away_team = score_table.find_all('tr')[away_t_row].find_all('td')[away_t_col].text.strip().lower()\n",
    "    ascore = float(score_table.find_all('tr')[away_t_row].find_all('td')[away_s_col].text.strip())\n",
    "    hscore = float(score_table.find_all('tr')[home_t_row].find_all('td')[home_s_col].text.strip())\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"     \n",
    "\n",
    "    if home_team == 'texas':\n",
    "        rush_table = tables[10]\n",
    "        pass_table = tables[12]\n",
    "        rec_table = tables[14]\n",
    "    else:\n",
    "        rush_table = tables[9]\n",
    "        pass_table = tables[11]\n",
    "        rec_table = tables[13]\n",
    "    \n",
    "    # rush stats\n",
    "    rush_2d = []\n",
    "    temp = []\n",
    "    for row in rush_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rush_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rush_col = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    rush_data = pd.DataFrame(rush_2d)\n",
    "    rush_data.columns = rush_col\n",
    "\n",
    "    # pass stats\n",
    "    pass_2d = []\n",
    "    temp = []\n",
    "    for row in pass_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            pass_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    for row in pass_2d:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "\n",
    "    pass_col = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_2d)\n",
    "    pass_data.columns = pass_col\n",
    "\n",
    "    # pass stats\n",
    "    rec_2d = []\n",
    "    temp = []\n",
    "    for row in rec_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rec_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rec_col = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "            \n",
    "    frames = [pass_2d, rush_2d, rec_2d]\n",
    "    for frame in frames:\n",
    "        for i in range(0,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_2d)\n",
    "    rec_data.columns = rec_col\n",
    "\n",
    "    full_game_data = pd.merge(pass_data, rush_data, how = \"outer\", on = \"Player\")\n",
    "    full_game_data = pd.merge(full_game_data, rec_data, how = 'outer', on = \"Player\")\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "\n",
    "    master_stats_2 = pd.concat([master_stats_2, full_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_2.to_csv('master_stats_2.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Links from UT master results (list for post 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2022': ['https://texassports.com/sports/football/stats/2022/ulm/boxscore/14707', 'https://texassports.com/sports/football/stats/2022/alabama/boxscore/14708', 'https://texassports.com/sports/football/stats/2022/utsa/boxscore/14709', 'https://texassports.com/sports/football/stats/2022/texas-tech/boxscore/14710', 'https://texassports.com/sports/football/stats/2022/west-virginia/boxscore/14711', 'https://texassports.com/sports/football/stats/2022/oklahoma/boxscore/14712', 'https://texassports.com/sports/football/stats/2022/iowa-state/boxscore/14713', 'https://texassports.com/sports/football/stats/2022/oklahoma-state/boxscore/14714', 'https://texassports.com/sports/football/stats/2022/kansas-state/boxscore/14715', 'https://texassports.com/sports/football/stats/2022/tcu/boxscore/14716', 'https://texassports.com/sports/football/stats/2022/kansas/boxscore/14717', 'https://texassports.com/sports/football/stats/2022/baylor/boxscore/14718', 'https://texassports.com/sports/football/stats/2022/washington/boxscore/15459'], '2021': ['https://texassports.com/sports/football/stats/2021/louisiana/boxscore/14136', 'https://texassports.com/sports/football/stats/2021/arkansas/boxscore/14137', 'https://texassports.com/sports/football/stats/2021/rice/boxscore/14138', 'https://texassports.com/sports/football/stats/2021/texas-tech/boxscore/14139', 'https://texassports.com/sports/football/stats/2021/tcu/boxscore/14140', 'https://texassports.com/sports/football/stats/2021/oklahoma/boxscore/14141', 'https://texassports.com/sports/football/stats/2021/oklahoma-state/boxscore/14142', 'https://texassports.com/sports/football/stats/2021/baylor/boxscore/14143', 'https://texassports.com/sports/football/stats/2021/iowa-state/boxscore/14144', 'https://texassports.com/sports/football/stats/2021/kansas/boxscore/14145', 'https://texassports.com/sports/football/stats/2021/west-virginia/boxscore/14146', 'https://texassports.com/sports/football/stats/2021/kansas-state/boxscore/14147'], '2020': ['https://texassports.com/sports/football/stats/2020/utep/boxscore/13653', 'https://texassports.com/sports/football/stats/2020/texas-tech/boxscore/13563', 'https://texassports.com/sports/football/stats/2020/tcu/boxscore/13566', 'https://texassports.com/sports/football/stats/2020/oklahoma/boxscore/13561', 'https://texassports.com/sports/football/stats/2020/baylor/boxscore/13564', 'https://texassports.com/sports/football/stats/2020/oklahoma-state/boxscore/13568', 'https://texassports.com/sports/football/stats/2020/west-virginia/boxscore/13863', 'https://texassports.com/sports/football/stats/2020/iowa-state/boxscore/13567', 'https://texassports.com/sports/football/stats/2020/kansas-state/boxscore/13652', 'https://texassports.com/sports/football/stats/2020/colorado/boxscore/13911'], '2019': ['hthttps://texassports.com/boxscore.aspx?path=football&id=12601', 'https://texassports.com/boxscore.aspx?path=football&id=12602', 'https://texassports.com/boxscore.aspx?path=football&id=12603', 'https://texassports.com/boxscore.aspx?path=football&id=12604', 'https://texassports.com/boxscore.aspx?path=football&id=12605', 'https://texassports.com/boxscore.aspx?path=football&id=12606', 'https://texassports.com/boxscore.aspx?path=football&id=12607', 'https://texassports.com/boxscore.aspx?id=12608&path=football', 'https://texassports.com/boxscore.aspx?path=football&id=12609', 'https://texassports.com/boxscore.aspx?path=football&id=12610', 'https://texassports.com/sports/football/stats/2019/baylor/boxscore/12611', 'https://texassports.com/sports/football/stats/2019/texas-tech/boxscore/12612', 'https://texassports.com/sports/football/stats/2019/utah/boxscore/13530'], '2018': ['https://texassports.com/boxscore.aspx?path=football&id=11894', 'https://texassports.com/boxscore.aspx?path=football&id=11895', 'https://texassports.com/boxscore.aspx?id=11896&path=football', 'https://texassports.com/boxscore.aspx?path=football&id=11897', 'https://texassports.com/boxscore.aspx?path=football&id=11898', 'https://texassports.com/boxscore.aspx?path=football&id=11899', 'https://texassports.com/boxscore.aspx?path=football&id=11900', 'https://texassports.com/boxscore.aspx?id=11903&path=football', 'https://texassports.com/boxscore.aspx?path=football&id=11904', 'https://texassports.com/boxscore.aspx?path=football&id=11905', 'https://texassports.com/boxscore.aspx?path=football&id=11906', 'https://texassports.com/boxscore.aspx?path=football&id=11907', 'https://texassports.com/boxscore.aspx?path=football&id=12705', 'https://texassports.com/boxscore.aspx?id=12717&path=football'], '2017': ['http://www.texassports.com/boxscore.aspx?id=10202&path=football', 'http://www.texassports.com/boxscore.aspx?id=10203&path=football', 'http://www.texassports.com/boxscore.aspx?id=10204&path=football', 'http://www.texassports.com/boxscore.aspx?id=10205&path=football', 'http://www.texassports.com/boxscore.aspx?path=football&id=10206', 'http://www.texassports.com/boxscore.aspx?id=10207&path=football', 'https://www.texassports.com/boxscore.aspx?id=10208&path=football', 'http://texassports.com/boxscore.aspx?id=10209&path=football', 'http://www.texassports.com/boxscore.aspx?id=10210&path=football', 'http://www.texassports.com/boxscore.aspx?id=10211&path=football', 'http://www.texassports.com/boxscore.aspx?id=10212&path=football', 'http://www.texassports.com/boxscore.aspx?id=10213&path=football', 'http://www.texassports.com/boxscore.aspx?id=11873&path=football'], '2016': ['http://www.texassports.com/boxscore.aspx?path=football&id=9486', 'http://www.texassports.com/boxscore.aspx?path=football&id=9491', 'http://admin.texassports.com/boxscore.aspx?id=10036&path=football', 'http://www.texassports.com/boxscore.aspx?path=football&id=9493', 'http://texassports.com/boxscore.aspx?path=football&id=9495', 'http://www.texassports.com/boxscore.aspx?path=football&id=9496', 'http://www.texassports.com/boxscore.aspx?path=football&id=9502', 'http://www.texassports.com/boxscore.aspx?path=football&id=9497', 'http://www.texassports.com/boxscore.aspx?path=football&id=9498', 'http://www.texassports.com/boxscore.aspx?path=football&id=9499', 'http://www.texassports.com/boxscore.aspx?path=football&id=9500', 'http://www.texassports.com/boxscore.aspx?path=football&id=9501'], '2015': ['http://www.texassports.com/boxscore.aspx?path=football&id=8606', 'http://www.texassports.com/boxscore.aspx?path=football&id=8607', 'http://www.texassports.com/boxscore.aspx?path=football&id=8608', 'http://www.texassports.com/boxscore.aspx?path=football&id=8609', 'http://texassports.com/boxscore.aspx?path=football&id=8610', 'http://www.texassports.com/boxscore.aspx?path=football&id=8611', 'http://www.texassports.com/boxscore.aspx?path=football&id=8612', 'http://www.texassports.com/boxscore.aspx?path=football&id=8613', 'http://www.texassports.com/boxscore.aspx?path=football&id=8614', 'http://www.texassports.com/boxscore.aspx?path=football&id=8615', 'http://www.texassports.com/boxscore.aspx?path=football&id=8616', 'http://www.texassports.com/boxscore.aspx?path=football&id=8617']}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "driver.quit()\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# get most recent year\n",
    "temp = table_list[0].find('td').get_text()\n",
    "year_index = temp.find('\\n')\n",
    "year = temp[year_index - 4:year_index]\n",
    "\n",
    "years_past_2022 = int(year) - 2022\n",
    "\n",
    "# link dictionary\n",
    "link_dict = {}\n",
    "for table in table_list[:8 + years_past_2022]:\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[2:]\n",
    "    box_score_links = []\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.a['href']\n",
    "            box_score_links.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    link_dict[year] = box_score_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ut website scrape (2015-2022) missing la tech 2019 (plus http://texassports.com/boxscore.aspx?path=football&id=8599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 100/100 [02:43<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# use selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--ignore-certificate-errors\")\n",
    "options.add_argument(\"--incognito\")\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# retry mechanism\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "def make_request(url):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"POST\"],\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "driver.get('https://texassports.com/sports/2013/7/21/FB_0721134841.aspx?id=131')\n",
    "texas_sports_soup = BeautifulSoup(driver.page_source)\n",
    "table_list = texas_sports_soup.find_all(\"table\")\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_3 = pd.DataFrame(stats)\n",
    "\n",
    "# link list\n",
    "links_2015_2022 = []\n",
    "\n",
    "# get most recent year\n",
    "temp = table_list[0].find('td').get_text()\n",
    "year_index = temp.find('\\n')\n",
    "year = temp[year_index - 4:year_index]\n",
    "\n",
    "years_past_2022 = int(year) - 2022\n",
    "\n",
    "for table in table_list[:8 + years_past_2022]:\n",
    "    # get year\n",
    "    temp = table.find('td').get_text()\n",
    "    year_index = temp.find('\\n')\n",
    "    year = temp[year_index - 4:year_index]\n",
    "\n",
    "    # get box score links\n",
    "    rows = table.tbody.find_all('tr')[2:]\n",
    "    for row in rows:\n",
    "        box_score = row.find_all('td')[-1]\n",
    "        try:\n",
    "            link_temp = box_score.a['href']\n",
    "            links_2015_2022.append(link_temp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# deal with mislinked la tech 2019\n",
    "links_2015_2022[links_2015_2022.index('hthttps://texassports.com/boxscore.aspx?path=football&id=12601')] = 'https://texassports.com/boxscore.aspx?path=football&id=12601'\n",
    "\n",
    "# texas vs arkansas 2014\n",
    "links_2015_2022.append('http://texassports.com/boxscore.aspx?path=football&id=8599')\n",
    "\n",
    "for i in tqdm(range(len(links_2015_2022)), desc = \"Database building...\"):\n",
    "# for i in range(len(links_2015_2022)):\n",
    "    url = links_2015_2022[i]\n",
    "    # driver.get(url)\n",
    "    # driver.implicitly_wait(2) # wait a bit\n",
    "    # page_source = driver.page_source\n",
    "    # soup = BeautifulSoup(page_source)\n",
    "\n",
    "    response = make_request(url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        # print(url)\n",
    "        driver.get(url)\n",
    "        # driver.implicitly_wait(2) # wait a bit\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source)\n",
    "\n",
    "    individual_stats = soup.find('section', id='individual-stats')\n",
    "    tables = individual_stats.find_all('table')\n",
    "\n",
    "    score_table = soup.find('table')\n",
    "    score_table = score_table.find_all('td')\n",
    "    for i in range(1, len(score_table)):\n",
    "        try:\n",
    "            x = int(score_table[i+1].text)\n",
    "        except:\n",
    "            ascore = float(score_table[i].text)\n",
    "            home_team = score_table[i+1].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "            break\n",
    "\n",
    "    away_team = score_table[0].find_all('span', class_='hide-on-small-down')[0].get_text().strip().lower()\n",
    "    hscore = float(score_table[-1].text)\n",
    "\n",
    "    home_team = home_team.replace(\"Winner\", \"\")\n",
    "    away_team = away_team.replace(\"Winner\", \"\")\n",
    "\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get date\n",
    "    big_html = soup.text\n",
    "    date_index = big_html.find('Date:')\n",
    "    date_endex = big_html.find('Site:')\n",
    "    date = big_html[date_index + 6: date_endex].strip()\n",
    "    date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "\n",
    "    # make gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "\n",
    "    if home_team == 'texas':\n",
    "        tex_pass = tables[1]\n",
    "        tex_rush = tables[3]\n",
    "        tex_rec = tables[5]\n",
    "    else:\n",
    "        tex_pass = tables[0]\n",
    "        tex_rush = tables[2]\n",
    "        tex_rec = tables[4]\n",
    "\n",
    "    tex_pass_stats = tex_pass.find_all('td')\n",
    "    for i in range(len(tex_pass_stats)):  # convert passers to text\n",
    "        tex_pass_stats[i] = tex_pass_stats[i].text.strip()\n",
    "    passer_temp = []\n",
    "    tex_pass_stats_final = []\n",
    "    for i in range(len(tex_pass_stats)):\n",
    "        passer_temp.append(tex_pass_stats[i])\n",
    "        if len(passer_temp)/8 == 1:\n",
    "            tex_pass_stats_final.append(passer_temp)\n",
    "            passer_temp = []\n",
    "    for i in range(len(tex_pass_stats_final)):\n",
    "        for j in range(1, len(tex_pass_stats_final[i])):\n",
    "            tex_pass_stats_final[i][j] = float(tex_pass_stats_final[i][j])\n",
    "    tex_pass_stats_final = pd.DataFrame(tex_pass_stats_final)\n",
    "    tex_pass_stats_final.columns = ['Player', 'Completions', 'Pass Attempts', 'Pass Yards', 'Passing TDs', 'Interceptions', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    tex_rush_stats = tex_rush.find_all('td')\n",
    "    for i in range(len(tex_rush_stats)):  # convert passers to text\n",
    "        tex_rush_stats[i] = tex_rush_stats[i].text.strip()\n",
    "    rusher_temp = []\n",
    "    tex_rush_stats_final = []\n",
    "    for i in range(len(tex_rush_stats)):\n",
    "        rusher_temp.append(tex_rush_stats[i])\n",
    "        if len(rusher_temp)/8 == 1:\n",
    "            tex_rush_stats_final.append(rusher_temp)\n",
    "            rusher_temp = []\n",
    "    for i in range(len(tex_rush_stats_final)):\n",
    "        for j in range(1, len(tex_rush_stats_final[i])):\n",
    "            tex_rush_stats_final[i][j] = float(tex_rush_stats_final[i][j])\n",
    "    tex_rush_stats_final = pd.DataFrame(tex_rush_stats_final)\n",
    "    tex_rush_stats_final.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    tex_rec_stats = tex_rec.find_all('td')\n",
    "    for i in range(len(tex_rec_stats)):  # convert passers to text\n",
    "        tex_rec_stats[i] = tex_rec_stats[i].text.strip()\n",
    "    recer_temp = []\n",
    "    tex_rec_stats_final = []\n",
    "    for i in range(len(tex_rec_stats)):\n",
    "        recer_temp.append(tex_rec_stats[i])\n",
    "        if len(recer_temp)/5 == 1:\n",
    "            tex_rec_stats_final.append(recer_temp)\n",
    "            recer_temp = []\n",
    "    for i in range(len(tex_rec_stats_final)):\n",
    "        for j in range(1, len(tex_rec_stats_final[i])):\n",
    "            tex_rec_stats_final[i][j] = float(tex_rec_stats_final[i][j])\n",
    "    tex_rec_stats_final = pd.DataFrame(tex_rec_stats_final)\n",
    "    tex_rec_stats_final.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        tex_pass_stats_final, tex_rush_stats_final, how = \"outer\", on = \"Player\")\n",
    "\n",
    "    full_game_stats = pd.merge(\n",
    "        full_game_stats, tex_rec_stats_final, how = 'outer', on = \"Player\")\n",
    "\n",
    "    full_game_stats = full_game_stats.fillna(0)\n",
    "\n",
    "    full_game_stats['GameID'] = gameid\n",
    "    full_game_stats['Date'] = date\n",
    "    full_game_stats['Home Team'] = home_team\n",
    "    full_game_stats['Away Team'] = away_team\n",
    "    full_game_stats['Home Score'] = hscore\n",
    "    full_game_stats['Away Score'] = ascore\n",
    "    full_game_stats['Texas Result'] = tex_win\n",
    "    full_game_stats['Link'] = url\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_3 = pd.concat([master_stats_3, full_game_stats], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_3.to_csv(\"master_stats_3.csv\", index = False)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get glitched blue box scores kansas and nebraska 2009 (probably wouldn't have bothered with these if I knew it was just two games but its nice not to do manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_4 = pd.DataFrame(stats)\n",
    "\n",
    "link_list = ['https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/big12fb.html', # nebraska 2009\n",
    "             'https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html'] # kansas 2009\n",
    "\n",
    "for i in tqdm(range(len(link_list)), desc = \"Database building...\"):\n",
    "    link = link_list[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/2009-2010/ut11.html') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex - 3].strip()\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    tables = temp_box_soup.find_all(\"table\")\n",
    "    score_table = tables[3]\n",
    "    away_t_row = 1\n",
    "    home_t_row = 2\n",
    "\n",
    "    away_t_col = 0\n",
    "    home_t_col = 0\n",
    "\n",
    "    away_s_col = 5\n",
    "    home_s_col = 5\n",
    "\n",
    "    home_team = score_table.find_all('tr')[home_t_row].find_all('td')[home_t_col].text.strip().lower()\n",
    "    away_team = score_table.find_all('tr')[away_t_row].find_all('td')[away_t_col].text.strip().lower()\n",
    "    ascore = float(score_table.find_all('tr')[away_t_row].find_all('td')[away_s_col].text.strip())\n",
    "    hscore = float(score_table.find_all('tr')[home_t_row].find_all('td')[home_s_col].text.strip())\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"     \n",
    "\n",
    "    if home_team == 'texas':\n",
    "        rush_table = tables[11]\n",
    "        pass_table = tables[13]\n",
    "        rec_table = tables[15]\n",
    "    else:\n",
    "        rush_table = tables[10]\n",
    "        pass_table = tables[12]\n",
    "        rec_table = tables[14]\n",
    "\n",
    "    # rush stats\n",
    "    rush_2d = []\n",
    "    temp = []\n",
    "    for row in rush_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rush_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rush_col = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    rush_data = pd.DataFrame(rush_2d)\n",
    "    rush_data.columns = rush_col\n",
    "\n",
    "    # pass stats\n",
    "    pass_2d = []\n",
    "    temp = []\n",
    "    for row in pass_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            pass_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    for row in pass_2d:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "\n",
    "    pass_col = ['Player', 'Completions', 'Pass Attempts', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_2d)\n",
    "    pass_data.columns = pass_col\n",
    "\n",
    "    # pass stats\n",
    "    rec_2d = []\n",
    "    temp = []\n",
    "    for row in rec_table.find_all('tr')[1:]:\n",
    "        for val in row.find_all('td'):\n",
    "            temp.append(val.text.strip())\n",
    "        if temp[0] == '':\n",
    "            pass\n",
    "        else:\n",
    "            rec_2d.append(temp)\n",
    "        temp = []\n",
    "\n",
    "    rec_col = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "            \n",
    "    frames = [pass_2d, rush_2d, rec_2d]\n",
    "    for frame in frames:\n",
    "        for i in range(0,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_2d)\n",
    "    rec_data.columns = rec_col\n",
    "\n",
    "    full_game_data = pd.merge(pass_data, rush_data, how = \"outer\", on = \"Player\")\n",
    "    full_game_data = pd.merge(full_game_data, rec_data, how = 'outer', on = \"Player\")\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "\n",
    "    numeric_cols = full_game_data.select_dtypes(include='number').columns\n",
    "    full_game_data[numeric_cols] = full_game_data[numeric_cols].astype(float)\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_4 = pd.concat([master_stats_4, full_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "\n",
    "master_stats_4.to_csv(\"master_stats_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2008 (i do not like 2008\n",
    "        i do not like it in a gate\n",
    "            i do not like it when it skate\n",
    "                i do not like 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Database building...: 100%|██████████| 13/13 [00:07<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# set up master dataframe\n",
    "stats = {\n",
    "    'Player': [],\n",
    "    'Completions': [],\n",
    "    'Pass Attempts': [],\n",
    "    'Interceptions': [],\n",
    "    'Pass Yards': [],\n",
    "    'Passing TDs': [],\n",
    "    'Longest Pass': [],\n",
    "    'Sacks Taken': [],\n",
    "    'Rush Attempts': [],\n",
    "    'Rush Yards Gained': [],\n",
    "    'Rush Yards Lost': [],\n",
    "    'Net Rush Yards': [],\n",
    "    'Rushing TDs': [],\n",
    "    'Longest Rush': [],\n",
    "    'Yards Per Rush': [],\n",
    "    'Catches': [],\n",
    "    'Receiving Yards': [],\n",
    "    'Receiving TDs': [],\n",
    "    'Longest Reception': [],\n",
    "    'GameID': [],\n",
    "    'Link': []\n",
    "}\n",
    "master_stats_5 = pd.DataFrame(stats)\n",
    "\n",
    "link_list = ['http://stats.texassports.com/sports/m-footbl/2008-2009/ut1.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut2.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut3.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut4.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut5.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut6.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut7.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut8.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut9.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut10.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut11.html',\n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut12.html',            \n",
    "             'http://stats.texassports.com/sports/m-footbl/2008-2009/ut13.html']\n",
    "\n",
    "for i in tqdm(range(len(link_list)), desc = \"Database building...\"):\n",
    "    # Get full page soup\n",
    "    link = link_list[i]\n",
    "    response = make_request(link)\n",
    "    temp_box_soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    if response == '':\n",
    "        driver.get(link)\n",
    "        # driver.get('https://stats.texassports.com/custompages/sports/m-footbl/archive/stats/06/ut11.htm') # for troubleshooting\n",
    "        temp_box_soup = BeautifulSoup(driver.page_source)\n",
    "    temp_text = temp_box_soup.text\n",
    "    temp_text = temp_text.replace(\"Texas Longhorns\", \"Texas\")\n",
    "    temp_text = temp_text.replace('TEXAS', 'Texas')\n",
    "\n",
    "    # Get game date\n",
    "    date_index = temp_text.find('Date: ')\n",
    "    date_endex = temp_text.find(\"Site: \")\n",
    "    date = temp_text[date_index + 6: date_endex].strip()\n",
    "    if date == \"0ct 10, 1959\":\n",
    "        date = \"Oct 10, 1959\"\n",
    "    date = date.replace(\",\", \"\")\n",
    "    date = date[:-4] + ',' + date[-4:]\n",
    "    date = date.replace(\"Sept\", \"Sep\")\n",
    "    date = date.replace(\" \", \"\")\n",
    "    try:\n",
    "        date = datetime.strptime(date, \"%b%d,%Y\")\n",
    "    except ValueError:\n",
    "        date = datetime.strptime(date, \"%b.%d,%Y\")      \n",
    "\n",
    "    # Get away team\n",
    "    away_index = temp_text.find('Photo Gallery')\n",
    "    away_endex = temp_text.find(' vs ')\n",
    "    away_team = temp_text[away_index + 13: away_endex].strip().lower()\n",
    "    if away_team == \"xas\":\n",
    "        away_team = \"texas\"\n",
    "    elif away_team == \"ylor\":\n",
    "        away_team = \"baylor\"\n",
    "\n",
    "    # Get home team\n",
    "    home_index = temp_text.find(' vs ')\n",
    "    home_endex = temp_text.find(' (')\n",
    "    home_team = temp_text[home_index + 4: home_endex].strip().lower()\n",
    "\n",
    "    # get away score\n",
    "    temp_index = temp_text.find('Score by Quarters     1  2  3  4   Score')\n",
    "    temp_text_new = temp_text[temp_index:]\n",
    "    temp_index = temp_text_new.find('\\n')\n",
    "    temp_text_new = temp_text_new[temp_index + 1:]\n",
    "    temp_index = temp_text_new.find('\\n')\n",
    "    temp_text_new = temp_text_new[temp_index + 1:]\n",
    "    ascore_index = temp_text_new.find(' - ') + 3\n",
    "    ascore_endex = temp_text_new.find('\\n')\n",
    "    ascore = temp_text_new[ascore_index:ascore_endex].strip()\n",
    "    ascore = float(ascore)\n",
    "\n",
    "    # get home score\n",
    "    temp_text_new = temp_text_new[ascore_endex + 1:]\n",
    "    hscore_index = temp_text_new.find(' - ') + 3\n",
    "    hscore_endex = temp_text_new.find('\\n')\n",
    "    hscore = temp_text_new[hscore_index:hscore_endex].strip()\n",
    "    hscore = float(hscore)\n",
    "\n",
    "    # did texas win?\n",
    "    if (home_team == 'texas' and hscore > ascore) or (away_team == 'texas' and hscore < ascore):\n",
    "        tex_win = \"Win\"\n",
    "    elif (home_team == 'texas' and hscore < ascore) or (away_team == 'texas' and hscore > ascore):\n",
    "        tex_win = \"Loss\"\n",
    "    else:\n",
    "        tex_win = \"Tie\"\n",
    "\n",
    "    # get UT box score text\n",
    "    temp = temp_box_soup.text\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    index = temp.find(\"Individual Statistics\")\n",
    "    temp = temp[index + 21:]\n",
    "    temp = temp.replace('Texas Longhorns', 'Texas')\n",
    "    temp = temp.replace('TEXAS', 'Texas')\n",
    "\n",
    "    split = temp.find('Field goal attempts')\n",
    "    if home_team == 'texas': \n",
    "        temp = temp[split:]\n",
    "    else: \n",
    "        temp = temp[:split]\n",
    "\n",
    "    # Truncate box score for rushing stats\n",
    "    rush_start = temp.find('Rushing              No Gain Loss  Net TD Lg  Avg')\n",
    "    rush_end = temp.find('Passing              ') - 2\n",
    "    rush_temp = temp[rush_start:rush_end]\n",
    "\n",
    "    # Get rushing stats\n",
    "    rush_stats = []    \n",
    "    line_break = rush_temp.find('\\n')\n",
    "    header = rush_temp[0:line_break].split()\n",
    "    rush_stats.append(header)\n",
    "    rush_temp = rush_temp[line_break:]\n",
    "    line_break = rush_temp.find('\\n')\n",
    "    rush_temp = rush_temp[line_break + 1:]\n",
    "\n",
    "    # Now rush temp has no header\n",
    "    line_break = rush_temp.find('\\n')\n",
    "    rush_temp = rush_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = rush_temp.find('\\n')\n",
    "        line = rush_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if rush_temp.find('\\n') == -1:\n",
    "            line = rush_temp\n",
    "            game_stat = line.split()          \n",
    "            rush_stats.append(game_stat)\n",
    "            rush_temp = rush_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 8: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            rush_stats.append(game_stat)\n",
    "            rush_temp = rush_temp[line_break + 1:]\n",
    "    \n",
    "    # Truncate box score for passing stats\n",
    "    pass_start = temp.find('Passing              ')\n",
    "    pass_end = temp.find('Receiving             No.  Yds   TD Long') - 3\n",
    "    pass_temp = temp[pass_start:pass_end]\n",
    "\n",
    "    # Get passing stats\n",
    "    pass_stats = []    \n",
    "    line_break = pass_temp.find('\\n')\n",
    "    header = pass_temp[0:line_break].split()\n",
    "    pass_stats.append(header)\n",
    "    pass_temp = pass_temp[line_break:]\n",
    "    line_break = pass_temp.find('\\n')\n",
    "    pass_temp = pass_temp[line_break + 1:]\n",
    "\n",
    "    # Now pass temp has no header\n",
    "    line_break = pass_temp.find('\\n')\n",
    "    pass_temp = pass_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = pass_temp.find('\\n')\n",
    "        line = pass_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if pass_temp.find('\\n') == -1:\n",
    "            line = pass_temp\n",
    "            game_stat = line.split()\n",
    "            pass_stats.append(game_stat)\n",
    "            pass_temp = pass_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 6: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            pass_stats.append(game_stat)\n",
    "            pass_temp = pass_temp[line_break + 1:]\n",
    "    \n",
    "    # Truncate box score for rec stats\n",
    "    rec_start = temp.find('Receiving             No.  Yds   TD Long')\n",
    "    rec_end = temp.find('Punting               No.  Yds   Avg Long In20   TB')\n",
    "    rec_temp = temp[rec_start:rec_end]\n",
    "\n",
    "    # Get rec stats\n",
    "    rec_stats = []    \n",
    "    line_break = rec_temp.find('\\n')\n",
    "    header = rec_temp[0:line_break].split()\n",
    "    rec_stats.append(header)\n",
    "    rec_temp = rec_temp[line_break:]\n",
    "    line_break = rec_temp.find('\\n')\n",
    "    rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "    # Now rec temp has no header\n",
    "    line_break = rec_temp.find('\\n')\n",
    "    rec_temp = rec_temp[line_break + 1:]\n",
    "    while True:\n",
    "        line_break = rec_temp.find('\\n')\n",
    "        line = rec_temp[0:line_break + 1]\n",
    "        game_stat = line.split()\n",
    "        if rec_temp.find('\\n') == -1:\n",
    "            line = rec_temp\n",
    "            game_stat = line.split()\n",
    "            rec_stats.append(game_stat)\n",
    "            rec_temp = rec_temp[line_break + 1:]\n",
    "            break\n",
    "        else:\n",
    "            # combines first n name columns\n",
    "            while len(game_stat) > 5: \n",
    "                name = game_stat[0] + ' ' + game_stat[1]\n",
    "                stats = game_stat[2:]\n",
    "                game_stat = [name] + stats\n",
    "            rec_stats.append(game_stat)\n",
    "            rec_temp = rec_temp[line_break + 1:]\n",
    "\n",
    "    ##############################################################\n",
    "    # Now that we have the stats in 2d lists, we need to make sure they aren't just strings\n",
    "    # First, we must address the formatting of the passing cmp-att-int format\n",
    "    for row in pass_stats:\n",
    "        new_element = row.pop(1).split('-')\n",
    "        row[1:1] = new_element\n",
    "    \n",
    "    # Next, we must make sure the elements are floats and not strings\n",
    "    frames = [pass_stats, rush_stats, rec_stats]\n",
    "    for frame in frames:\n",
    "        for i in range(1,len(frame)):\n",
    "            for j in range(1,len(frame[i])):\n",
    "                frame[i][j] = float(frame[i][j])\n",
    "                \n",
    "    # Now, we make the arrays into dataframes using panda\n",
    "    # admittedly i shouldve done this earlier but oh well\n",
    "    rush_data = pd.DataFrame(rush_stats[1:])\n",
    "    rush_data.columns = ['Player', 'Rush Attempts', 'Rush Yards Gained', 'Rush Yards Lost', 'Net Rush Yards', 'Rushing TDs', 'Longest Rush', 'Yards Per Rush']\n",
    "\n",
    "    pass_data = pd.DataFrame(pass_stats[1:])\n",
    "    pass_data.columns = ['Player', 'Pass Attempts', 'Completions', 'Interceptions', 'Pass Yards', 'Passing TDs', 'Longest Pass', 'Sacks Taken']\n",
    "\n",
    "    rec_data = pd.DataFrame(rec_stats[1:])\n",
    "    rec_data.columns = ['Player', 'Catches', 'Receiving Yards', 'Receiving TDs', 'Longest Reception']\n",
    "    \n",
    "    # Finally, time to merge the data into one full dataframe for the full game\n",
    "    full_game_data = pd.merge(\n",
    "        pass_data, rush_data, how = \"outer\", on = \"Player\"\n",
    "    )\n",
    "    full_game_data = pd.merge(\n",
    "        full_game_data, rec_data, how = 'outer', on = \"Player\"\n",
    "    )\n",
    "    full_game_data = full_game_data.fillna(0)\n",
    "\n",
    "    # small thing but i want to take the ellipsis out of the totals category\n",
    "    full_game_data = full_game_data.replace('Totals...', 'Total')\n",
    "\n",
    "    # now make the gameid\n",
    "    gameid = away_team.replace(\" \", \"\").lower() + '_' + home_team.replace(\" \", \"\").lower() + '_' + str(date.month) + '_' + str(date.day) + '_' + str(date.year)\n",
    "    gameid_list = [gameid]\n",
    "\n",
    "    '''\n",
    "    game_df = {'Home Team' : [home_team],\n",
    "            'Away Team' : [away_team],\n",
    "            'Home Score' : [hscore],\n",
    "            'Away Score' : [ascore],\n",
    "            'Texas Result' : [tex_win],\n",
    "            'Box Score' : [full_game_data]\n",
    "            }\n",
    "    \n",
    "    game_df = pd.DataFrame(game_df, index = gameid_list)\n",
    "\n",
    "    # finally append it to the master games\n",
    "    master_games = pd.concat([master_games, game_df], ignore_index = True)\n",
    "\n",
    "    # empty out game_df\n",
    "    game_df = pd.DataFrame()\n",
    "    '''\n",
    "\n",
    "    ##############################################################\n",
    "    # the last thing I want to do is to create one large dataframe with every single game performance ever\n",
    "    # this will contain duplicate players for their different performances in different games\n",
    "    # much less concise, much more usefull (probably)\n",
    "    # first add gameid column\n",
    "    full_game_data['GameID'] = gameid\n",
    "    full_game_data['Date'] = date\n",
    "    full_game_data['Home Team'] = home_team\n",
    "    full_game_data['Away Team'] = away_team\n",
    "    full_game_data['Home Score'] = hscore\n",
    "    full_game_data['Away Score'] = ascore\n",
    "    full_game_data['Texas Result'] = tex_win\n",
    "    full_game_data['Link'] = link\n",
    "\n",
    "    # now add it to the master stats\n",
    "    master_stats_5 = pd.concat([master_stats_5, full_game_data], ignore_index = True)\n",
    "\n",
    "    # finally empty out the full game dataframe\n",
    "    full_game_data = pd.DataFrame() \n",
    "        \n",
    "# print(master_stats_1)\n",
    "master_stats_5 = master_stats_5[master_stats_5[\"Player\"] != 0]\n",
    "master_stats_5.to_csv('master_stats_5.csv', index = False)\n",
    "# master_games.to_csv('master_games.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023 and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe i can adapt the old code one moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things i need to fix:\n",
    "- north texas glitch [done]\n",
    "- la tech 2019 (maybe this will run now) [done]\n",
    "- 3 games in 1998 [done]\n",
    "- arkansas 2014 [done]\n",
    "- add link to blue tables and new format [done]\n",
    "- 2008, kansas 2009, nebraska 2009 [done]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the master stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "master_stats_1 = pd.read_csv('master_stats_1.csv')\n",
    "master_stats_2 = pd.read_csv('master_stats_2.csv')\n",
    "master_stats_3 = pd.read_csv('master_stats_3.csv')\n",
    "master_stats_4 = pd.read_csv('master_stats_4.csv')\n",
    "master_stats_5 = pd.read_csv('master_stats_5.csv')\n",
    "\n",
    "master_stats = pd.concat([master_stats_1, \n",
    "                          master_stats_2, \n",
    "                          master_stats_3, \n",
    "                          master_stats_4, \n",
    "                          master_stats_5], \n",
    "                          ignore_index=True)\n",
    "master_stats.to_csv('master_stats.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up\n",
    "- give first and last name columns\n",
    "- strip the names\n",
    "- put names in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_names(row):\n",
    "    full_name = row['Last Name']\n",
    "    if pd.notna(full_name) and pd.isna(row['First Name']):\n",
    "        names = full_name.split()\n",
    "        if len(names) == 2:\n",
    "            row['First Name'] = names[0]\n",
    "            row['Last Name'] = names[1]\n",
    "    return row\n",
    "\n",
    "master_stats_test = pd.read_csv('master_stats.csv')\n",
    "\n",
    "# who the fuck did this to johnny walker 4 times i do not understand\n",
    "master_stats_test['Player'].replace('Walker. Johnny', 'Walker, Johnny', inplace = True)\n",
    "\n",
    "# split on commas\n",
    "master_stats_test[['Last Name', 'First Name']] = master_stats_test['Player'].str.split(pat=',', n=1, expand=True)\n",
    "master_stats_test = master_stats_test.drop('Player', axis=1)\n",
    "\n",
    "# strip the names\n",
    "master_stats_test['Last Name'] = master_stats_test['Last Name'].str.strip()\n",
    "master_stats_test['First Name'] = master_stats_test['First Name'].str.strip()\n",
    "\n",
    "# fix players with \"First Last\" Format\n",
    "master_stats_test = master_stats_test.apply(split_names, axis=1) \n",
    "\n",
    "# order the cols\n",
    "front_columns = ['First Name', 'Last Name']\n",
    "master_stats_test = master_stats_test[front_columns + [col for col in master_stats_test.columns if col not in front_columns]]\n",
    "\n",
    "# change totals to total\n",
    "master_stats_test['Last Name'].replace(\"Total\", \"Game\", inplace = True)\n",
    "master_stats_test['Last Name'].replace(\"Totals\", \"Game\", inplace = True)\n",
    "\n",
    "master_stats_test.to_csv('master_stats_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
